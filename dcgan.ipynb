{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from unittest import mock\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from tensorflow.python.estimator import estimator\n",
    "from tensorflow.python.training.basic_session_run_hooks import CheckpointSaverHook, meta_graph\n",
    "from tensorflow.python.platform import tf_logging as logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RUN_NAME = 'DCGAN_0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive, auth\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "# set paths\n",
    "ROOT = %pwd\n",
    "MODEL_DIR = 'gs://tputestingmnist/{}/'.format(RUN_NAME)\n",
    "LOG_DIR = MODEL_DIR\n",
    "GOOGLE_DRIVE_DIR = '/content/gdrive/My Drive/Programowanie/PixelGen/{}'.format(RUN_NAME)\n",
    "TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
    "\n",
    "auth.authenticate_user()\n",
    "  \n",
    "# Upload credentials to TPU.\n",
    "with tf.Session(TF_MASTER) as sess:    \n",
    "    with open('/content/adc.json', 'r') as f:\n",
    "        auth_info = json.load(f)\n",
    "    tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)\n",
    "\n",
    "# Configuration\n",
    "CHANNELS = 4\n",
    "R, C = 4, 4\n",
    "EXAMPLES = R * C\n",
    "LATENT_DIM = 128\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 150000\n",
    "EVAL_EPOCHS = 500\n",
    "\n",
    "PREFIX = RUN_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feeding data to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADD_NOISE_TO_EXAMPLE = True\n",
    "data_file = 'gs://tputestingmnist/characters_conditional_7.tfrecords'\n",
    "\n",
    "\n",
    "def parser(serialized_example):\n",
    "    \"\"\"Parses a single Example into image and label tensors.\"\"\"\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'image_transformed': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)   # label is unused\n",
    "        })\n",
    "\n",
    "    result_image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    result_image.set_shape([48 * 48 * 4])\n",
    "    result_image = tf.reshape(result_image, [48, 48, 4])[:,:,:CHANNELS]\n",
    "    # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
    "    result_image = tf.cast(result_image, dtype=tf.float32) / 127.5 - 1\n",
    "\n",
    "    input_image = tf.decode_raw(features['image_transformed'], tf.uint8)\n",
    "    input_image.set_shape([48 * 48 * 4])\n",
    "    input_image = tf.reshape(input_image, [48, 48, 4])[:,:,:CHANNELS]\n",
    "    # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
    "    input_image = tf.cast(input_image, dtype=tf.float32) / 127.5 - 1\n",
    "\n",
    "    return input_image, result_image\n",
    "\n",
    "\n",
    "def make_input_fn(is_training=True):\n",
    "    def input_fn(params):\n",
    "        batch_size = params['batch_size']\n",
    "        dataset = tf.data.TFRecordDataset(data_file).map(parser).cache().shuffle(batch_size)\n",
    "        if is_training:\n",
    "            dataset = dataset.repeat()\n",
    "        input_images, result_images = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
    "\n",
    "        if ADD_NOISE_TO_EXAMPLE:\n",
    "            input_images += tf.random_normal(shape=tf.shape(input_images), mean=0.0, stddev=0.1, dtype=tf.float32)\n",
    "\n",
    "        features = {\n",
    "            'image_input': input_images,\n",
    "            'image_result': result_images,\n",
    "            #         'random_noise': tf.random_uniform([params['batch_size'], LATENT_DIM], -1, 1, dtype=tf.float32)\n",
    "        }\n",
    "        return features, None\n",
    "    return input_fn\n",
    "\n",
    "\n",
    "def predict_input_fn(params):\n",
    "    batch_size = params['batch_size']\n",
    "    dataset = tf.data.TFRecordDataset(data_file).map(parser).cache().shuffle(batch_size)\n",
    "    input_images, _ = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
    "    return {'image_input': input_images}, None\n",
    "\n",
    "def images_to_zero_one(images):\n",
    "    return np.clip(np.array(images) * 0.5 + 0.5, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Creating sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_imgs(epoch, images):\n",
    "    # Rescale images to 0 - 1\n",
    "    images = images_to_zero_one(images)\n",
    "    fig, axs = plt.subplots(R, C)\n",
    "\n",
    "    for i in range(R):\n",
    "        for j in range(C):\n",
    "            axs[i,j].imshow(images[C*i + j])\n",
    "            axs[i,j].axis('off')\n",
    "          \n",
    "    fig.savefig(os.path.join(GOOGLE_DRIVE_DIR, '{}.png'.format(epoch)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KERNEL_SIZE = 4\n",
    "\n",
    "\n",
    "def _leaky_relu(x):\n",
    "    return tf.nn.leaky_relu(x, alpha=0.2)\n",
    "\n",
    "\n",
    "def _relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def _batch_norm(x, is_training, name):\n",
    "    return tf.layers.batch_normalization(x, momentum=0.8, epsilon=1e-5, training=is_training, name=name)\n",
    "\n",
    "\n",
    "def _dense(x, neurons, name, activation=None):\n",
    "    return tf.layers.dense(x, neurons, kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name=name,\n",
    "                           activation=activation)\n",
    "\n",
    "\n",
    "def _conv2d(x, filters, kernel_size, stride, name):\n",
    "    return tf.layers.conv2d(\n",
    "        x, filters, [kernel_size, kernel_size],\n",
    "        strides=[stride, stride], padding='same',\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name=name)\n",
    "\n",
    "\n",
    "def _deconv2d(x, filters, kernel_size, stride, name):\n",
    "    return tf.layers.conv2d_transpose(\n",
    "        x, filters, [kernel_size, kernel_size],\n",
    "        strides=[stride, stride], padding='same',\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=0.02), name=name)\n",
    "\n",
    "\n",
    "def _dropout(x, prob, name):\n",
    "    return tf.nn.dropout(x, keep_prob=prob, name=name)\n",
    "\n",
    "\n",
    "def convolution_block(x, filters, resize_factor, is_training, index, activation=_leaky_relu, dropout=False, batch_norm=False):\n",
    "    x = _conv2d(x, filters=filters, kernel_size=KERNEL_SIZE, stride=resize_factor, name='conv{}'.format(index))\n",
    "    if batch_norm:\n",
    "        x = _batch_norm(x, is_training, name='bnc{}'.format(index))\n",
    "    if dropout:\n",
    "        x = _dropout(x, prob=0.5, name='drop{}'.format(index))\n",
    "    x = activation(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def deconvolution_block(x, filters, resize_factor, is_training, index, activation=_relu, dropout=False, batch_norm=False):\n",
    "    x = _deconv2d(x, filters=filters, kernel_size=KERNEL_SIZE, stride=resize_factor, name='deconv{}'.format(index))\n",
    "    if batch_norm:\n",
    "        x = _batch_norm(x, is_training, name='bnc{}'.format(index))\n",
    "    if dropout:\n",
    "        x = _dropout(x, prob=0.5, name='drop{}'.format(index))\n",
    "    x = activation(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Dcgan:\n",
    "    @staticmethod\n",
    "    def discriminator(x, is_training=True, scope='Discriminator'):\n",
    "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "            x = convolution_block(x, 64, 2, is_training, 1)\n",
    "            x = convolution_block(x, 128, 2, is_training, 2)\n",
    "            x = convolution_block(x, 256, 2, is_training, 3)\n",
    "            x = convolution_block(x, 512, 1, is_training, 4)\n",
    "\n",
    "            x = tf.layers.Flatten()(x)\n",
    "            x = _dense(x, neurons=1, name='d_dense')\n",
    "\n",
    "            return x\n",
    "\n",
    "    @staticmethod\n",
    "    def generator(image, is_training=True, scope='Generator'):\n",
    "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "            # Encode\n",
    "            x = convolution_block(image, 64, 2, is_training, 11, dropout=False, batch_norm=False)\n",
    "            x = convolution_block(x, 128, 2, is_training, 12, dropout=False)\n",
    "            x = convolution_block(x, 256, 2, is_training, 13, dropout=False)\n",
    "            x = convolution_block(x, 512, 2, is_training, 14, dropout=False)\n",
    "            #             x = convolution_block(x, 512, 2, is_training, 15, dropout=False)\n",
    "            #             x = convolution_block(x, 512, 2, is_training, 16, dropout=False)\n",
    "\n",
    "\n",
    "            # Decode\n",
    "            #             x = deconvolution_block(x, 512, 2, is_training, 21)\n",
    "            #             x = deconvolution_block(x, 512, 2, is_training, 22)\n",
    "            x = deconvolution_block(x, 512, 2, is_training, 23)\n",
    "            x = deconvolution_block(x, 256, 2, is_training, 24, dropout=False)\n",
    "            x = deconvolution_block(x, 128, 2, is_training, 25, dropout=False)\n",
    "            x = deconvolution_block(x, 64, 2, is_training, 26, dropout=False)\n",
    "\n",
    "            x = _conv2d(x, filters=CHANNELS, kernel_size=KERNEL_SIZE, stride=1, name='final_conv')\n",
    "            x = tf.tanh(x)\n",
    "\n",
    "            return tf.concat((image, x), axis=1)\n",
    "        \n",
    "model = Dcgan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    # PREDICT #\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        random_noise = features['random_noise']\n",
    "        predictions = {'generated_images': model.generator(random_noise, is_training=False)}\n",
    "\n",
    "        return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    batch_size = params['batch_size']   # pylint: disable=unused-variable\n",
    "    real_images = features['real_images']\n",
    "    random_noise = features['random_noise']\n",
    "    generated_images = model.generator(random_noise, is_training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    # Discriminator loss\n",
    "    d_on_data_logits = tf.squeeze(model.discriminator(real_images))\n",
    "    d_on_data_labels = tf.ones_like(d_on_data_logits)\n",
    "\n",
    "    d_on_g_logits = tf.squeeze(model.discriminator(generated_images))\n",
    "    d_on_g_labels = tf.zeros_like(d_on_g_logits)\n",
    "\n",
    "    d_loss = tf.contrib.gan.losses.wargs.modified_discriminator_loss(\n",
    "        discriminator_real_outputs=d_on_data_logits,\n",
    "        discriminator_gen_outputs=d_on_g_logits,\n",
    "        reduction=tf.losses.Reduction.NONE,\n",
    "        label_smoothing=0.2\n",
    "    )\n",
    "\n",
    "    # Generator loss\n",
    "    g_loss = tf.contrib.gan.losses.wargs.modified_generator_loss(\n",
    "        discriminator_gen_outputs=d_on_g_logits,\n",
    "        reduction=tf.losses.Reduction.NONE\n",
    "    )\n",
    "\n",
    "    # TRAIN #\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        d_loss = tf.reduce_mean(d_loss)\n",
    "        g_loss = tf.reduce_mean(g_loss)\n",
    "        d_optimizer = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)\n",
    "        g_optimizer = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)\n",
    "\n",
    "        d_optimizer = tf.contrib.tpu.CrossShardOptimizer(d_optimizer)\n",
    "        g_optimizer = tf.contrib.tpu.CrossShardOptimizer(g_optimizer)\n",
    "\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            d_step = d_optimizer.minimize(d_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                                                                             scope='Discriminator'))\n",
    "            g_step = g_optimizer.minimize(g_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                                                                             scope='Generator'))\n",
    "\n",
    "            increment_step = tf.assign_add(tf.train.get_or_create_global_step(), 1)\n",
    "            joint_op = tf.group([d_step, g_step, increment_step])\n",
    "\n",
    "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=g_loss, train_op=joint_op)\n",
    "\n",
    "    # EVAL #\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        def _eval_metric_fn(d_loss, g_loss, d_real_labels, d_gen_lanels, d_real_logits, d_gen_logits):\n",
    "            return {\n",
    "                'discriminator_loss': tf.metrics.mean(d_loss),\n",
    "                'generator_loss': tf.metrics.mean(g_loss),\n",
    "                'discriminator_real_accuracy': tf.metrics.accuracy(labels=d_real_labels, predictions=tf.math.round(tf.sigmoid(d_real_logits))),\n",
    "                'discriminator_gen_accuracy': tf.metrics.accuracy(labels=d_gen_lanels, predictions=tf.math.round(tf.sigmoid(d_gen_logits)))\n",
    "            }\n",
    "\n",
    "        return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=tf.reduce_mean(g_loss),\n",
    "                                               eval_metrics=(_eval_metric_fn, [d_loss, g_loss, d_on_data_labels,\n",
    "                                                                               d_on_g_labels, d_on_data_logits, d_on_g_logits]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TF_MASTER)\n",
    "\n",
    "config = tf.contrib.tpu.RunConfig(\n",
    "    master=TF_MASTER,\n",
    "    save_checkpoints_steps=EVAL_EPOCHS,\n",
    "    save_checkpoints_secs=None,\n",
    "    save_summary_steps=EVAL_EPOCHS,\n",
    "    model_dir=MODEL_DIR,\n",
    "    keep_checkpoint_max=3,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(iterations_per_loop=1000))\n",
    "\n",
    "# TPU-based estimator used for TRAIN and EVAL\n",
    "est = tf.contrib.tpu.TPUEstimator(\n",
    "    model_fn=model_fn,\n",
    "    use_tpu=True,\n",
    "    config=config,\n",
    "    train_batch_size=BATCH_SIZE,\n",
    "    eval_batch_size=BATCH_SIZE)\n",
    "\n",
    "# CPU-based estimator used for PREDICT (generating images)\n",
    "cpu_est = tf.contrib.tpu.TPUEstimator(\n",
    "    model_fn=model_fn,\n",
    "    use_tpu=False,\n",
    "    config=config,\n",
    "    predict_batch_size=EXAMPLES)\n",
    "\n",
    "current_step = estimator._load_global_step_from_checkpoint_dir(MODEL_DIR)\n",
    "tf.logging.info('Starting training')\n",
    "\n",
    "while current_step < EPOCHS:\n",
    "    next_checkpoint = int(min(current_step + EVAL_EPOCHS, EPOCHS))\n",
    "    est.train(input_fn=make_input_fn(), max_steps=next_checkpoint)\n",
    "    current_step = next_checkpoint\n",
    "    tf.logging.info('Finished training step %d' % current_step)\n",
    "\n",
    "    # Evaluation\n",
    "    metrics = est.evaluate(input_fn=make_input_fn(False), steps=1)\n",
    "    tf.logging.info('Finished evaluating')\n",
    "    tf.logging.info(metrics)\n",
    "\n",
    "    # Render some generated images\n",
    "    generated_iter = cpu_est.predict(input_fn=noise_input_fn)\n",
    "    images = [p['generated_images'] for p in generated_iter]\n",
    "    save_imgs(current_step, images)\n",
    "    tf.logging.info('Finished generating images')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
