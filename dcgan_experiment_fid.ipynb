{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zfsf_Lx1TMli",
        "colab": {}
      },
      "source": [
        "from unittest import mock\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.estimator import estimator\n",
        "from tensorflow.python.training.basic_session_run_hooks import CheckpointSaverHook, meta_graph\n",
        "from tensorflow.python.platform import tf_logging as logging\n",
        "from google.colab import drive, auth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eDv_rgIffMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_experiment():\n",
        "    # Setup\n",
        "    \n",
        "    drive.mount('/content/gdrive')\n",
        "    # set paths\n",
        "    ROOT = %pwd\n",
        "    MODEL_DIR = 'gs://tputestingmnist/{}/'.format(RUN_NAME)\n",
        "    LOG_DIR = MODEL_DIR\n",
        "    GOOGLE_DRIVE_DIR = '/content/gdrive/My Drive/Programowanie/PixelGen/{}'.format(RUN_NAME)\n",
        "    TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    # Upload credentials to TPU.\n",
        "    with tf.Session(TF_MASTER) as sess:    \n",
        "        with open('/content/adc.json', 'r') as f:\n",
        "            auth_info = json.load(f)\n",
        "        tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)\n",
        "    \n",
        "    # Feeding data to the network\n",
        "\n",
        "    def parser(serialized_example):\n",
        "        \"\"\"Parses a single example into image and label tensors.\"\"\"\n",
        "        features = tf.parse_single_example(\n",
        "            serialized_example,\n",
        "            features={\n",
        "                'image_raw': tf.FixedLenFeature([], tf.string),\n",
        "                'label': tf.FixedLenFeature([], tf.int64)   # label is unused\n",
        "            })\n",
        "\n",
        "        image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
        "        image.set_shape([48 * 48 * 4])\n",
        "        image = tf.reshape(image, [48, 48, 4])[:,:,:CHANNELS]\n",
        "        # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
        "        image = tf.cast(image, dtype=tf.float32) / 127.5 - 1\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "    def make_input_fn(is_training=True):\n",
        "        def input_fn(params):\n",
        "            batch_size = params['batch_size']\n",
        "            dataset = tf.data.TFRecordDataset(data_file).map(parser).cache().shuffle(batch_size)\n",
        "            if is_training:\n",
        "                dataset = dataset.repeat()\n",
        "            images = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
        "\n",
        "            if ADD_NOISE_TO_EXAMPLE:\n",
        "                images += tf.random_normal(shape=tf.shape(images), mean=0.0, stddev=0.1, dtype=tf.float32)\n",
        "\n",
        "            features = {\n",
        "                'real_images': images,\n",
        "                'random_noise': tf.random_uniform([params['batch_size'], LATENT_DIM], -1, 1, dtype=tf.float32)\n",
        "            }\n",
        "            return features, None\n",
        "        return input_fn\n",
        "\n",
        "\n",
        "    def noise_input_fn(params):  \n",
        "        noise_dataset = tf.data.Dataset.from_tensors(tf.constant(np.random.uniform(-1, 1, (params['batch_size'], LATENT_DIM)), dtype=tf.float32))\n",
        "        return {'random_noise': noise_dataset.make_one_shot_iterator().get_next()}, None\n",
        "    \n",
        "    # Creating sample images\n",
        "    R, C = 4, 4\n",
        "    EXAMPLES = R * C\n",
        "\n",
        "\n",
        "    def images_to_zero_one(images):\n",
        "        return np.clip(np.array(images) * 0.5 + 0.5, 0., 1.)\n",
        "\n",
        "\n",
        "    def save_imgs(epoch, images):\n",
        "        if not os.path.exists(GOOGLE_DRIVE_DIR):\n",
        "            os.mkdir(GOOGLE_DRIVE_DIR)\n",
        "\n",
        "        # Rescale images to 0 - 1\n",
        "        images = images_to_zero_one(images)\n",
        "        fig, axs = plt.subplots(R, C)\n",
        "\n",
        "        for i in range(R):\n",
        "            for j in range(C):\n",
        "                axs[i,j].imshow(images[C*i + j])\n",
        "                axs[i,j].axis('off')\n",
        "\n",
        "        fig.savefig(os.path.join(GOOGLE_DRIVE_DIR, '{}.png'.format(epoch)))\n",
        "        plt.close()\n",
        "        \n",
        "        \n",
        "    # Models\n",
        "    def _leaky_relu(x):\n",
        "        return tf.nn.leaky_relu(x, alpha=ALPHA)\n",
        "\n",
        "\n",
        "    def _relu(x):\n",
        "        return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "    def _batch_norm(x, is_training, name):\n",
        "        return tf.layers.batch_normalization(x, momentum=0.8, epsilon=1e-5, \n",
        "                                             training=is_training, name=name)\n",
        "\n",
        "\n",
        "    def _dense(x, neurons, name, activation=None):\n",
        "        return tf.layers.dense(x, neurons, name=name, activation=activation,\n",
        "                               kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "    def _conv2d(x, filters, stride, name, activation=None):\n",
        "        return tf.layers.conv2d(x, filters, [KERNEL_SIZE, KERNEL_SIZE], \n",
        "                                strides=[stride, stride], activation=activation,\n",
        "                                padding='same', name=name,\n",
        "                                kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "    def _deconv2d(x, filters, stride, name, activation=None):\n",
        "        return tf.layers.conv2d_transpose(x, filters, [KERNEL_SIZE, KERNEL_SIZE],\n",
        "                                          strides=[stride, stride], activation=activation,\n",
        "                                          padding='same', name=name,\n",
        "                                          kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "    def _dropout(x, name):\n",
        "        return tf.nn.dropout(x, rate=DROPOUT_PROB, name=name)\n",
        "\n",
        "\n",
        "\n",
        "    def convolution_block(x, filters, resize_factor, is_training, index,\n",
        "                          activation=_leaky_relu, dropout=False, batch_norm=True):\n",
        "\n",
        "        x = _conv2d(x, filters=filters, stride=resize_factor, activation=activation, name='conv_{}'.format(index))\n",
        "\n",
        "        if batch_norm:\n",
        "            x = _batch_norm(x, is_training, name='bn_conv_{}'.format(index))\n",
        "\n",
        "        if dropout:\n",
        "            x = _dropout(x, name='drop_deconv_{}'.format(index))\n",
        "\n",
        "    #     x = activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def deconvolution_block(x, filters, resize_factor, is_training, index,\n",
        "                            activation=_relu, dropout=False, batch_norm=True):\n",
        "\n",
        "        x = _deconv2d(x, filters=filters, stride=resize_factor, activation=activation, name='deconv_{}'.format(index))\n",
        "\n",
        "        if batch_norm:\n",
        "            x = _batch_norm(x, is_training, name='bn_deconv_{}'.format(index))\n",
        "\n",
        "        if dropout:\n",
        "            x = _dropout(x, name='drop_deconv_{}'.format(index))\n",
        "\n",
        "    #     x = activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    class Dcgan:\n",
        "\n",
        "        @staticmethod\n",
        "        def discriminator(x, is_training=True, scope='Discriminator'):\n",
        "            with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "                x = convolution_block(x, 64, 2, is_training, 11, batch_norm=False)\n",
        "                x = convolution_block(x, 128, 2, is_training, 12)\n",
        "                x = convolution_block(x, 256, 2, is_training, 13)\n",
        "                x = convolution_block(x, 512, 2, is_training, 14)\n",
        "\n",
        "                x = tf.layers.Flatten()(x)\n",
        "                x = _dense(x, neurons=1, name='d_dense')\n",
        "\n",
        "                return x\n",
        "\n",
        "        @staticmethod\n",
        "        def generator(x, is_training=True, scope='Generator'):\n",
        "            with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "                x = _dense(x, 1024 * 3 * 3, activation=tf.nn.relu, name='g_dense')\n",
        "                x = tf.reshape(x, [-1, 3, 3, 1024])\n",
        "\n",
        "                x = deconvolution_block(x, 512, 2, is_training, 21)\n",
        "                x = deconvolution_block(x, 256, 2, is_training, 22)\n",
        "                x = deconvolution_block(x, 128, 2, is_training, 23)\n",
        "                x = deconvolution_block(x, CHANNELS, 2, is_training, 24, activation=tf.tanh, batch_norm=False)\n",
        "\n",
        "                return x\n",
        "\n",
        "    model = Dcgan()\n",
        "    \n",
        "    #FID    \n",
        "    def calculate_fid(images_1, images_2):\n",
        "        import sys\n",
        "        import functools\n",
        "        import time\n",
        "        from tensorflow.python.ops import array_ops\n",
        "        from tensorflow.python.ops import functional_ops\n",
        "        tfgan = tf.contrib.gan\n",
        "\n",
        "        # A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown\n",
        "        BATCH_SIZE = 1024\n",
        "\n",
        "        def inception_activations(images, num_splits=1):\n",
        "            print(images.shape)\n",
        "            sliced_images = images[:,0:48,0:48,:3]\n",
        "            size = 299\n",
        "            resized_images = tf.image.resize_bilinear(sliced_images, [size, size])\n",
        "            generated_images_list = array_ops.split(resized_images, num_or_size_splits = num_splits)\n",
        "            activations = functional_ops.map_fn(\n",
        "                fn = functools.partial(tfgan.eval.run_inception, output_tensor = 'pool_3:0'),\n",
        "                elems = array_ops.stack(generated_images_list),\n",
        "                parallel_iterations = 1,\n",
        "                back_prop = False,\n",
        "                swap_memory = True,\n",
        "                name = 'RunClassifier')\n",
        "            activations = array_ops.concat(array_ops.unstack(activations), 0)\n",
        "            return activations\n",
        "\n",
        "        act1 = inception_activations(images_1)\n",
        "        act2 = inception_activations(images_2)\n",
        "        return tfgan.eval.frechet_classifier_distance_from_activations(act1, act2)\n",
        "    \n",
        "    # Model function\n",
        "    def model_fn(features, labels, mode, params):\n",
        "        # PREDICT #\n",
        "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "            random_noise = features['random_noise']\n",
        "            generated_images = model.generator(random_noise, is_training=False)\n",
        "            predictions = {'generated_images': generated_images}\n",
        "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "        real_images = features['real_images']\n",
        "        random_noise = features['random_noise']\n",
        "        generated_images = model.generator(random_noise, is_training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
        "\n",
        "        # Discriminator loss\n",
        "        d_on_data_logits = tf.squeeze(model.discriminator(real_images))\n",
        "        d_on_data_labels = tf.ones_like(d_on_data_logits)\n",
        "\n",
        "        d_on_g_logits = tf.squeeze(model.discriminator(generated_images))\n",
        "        d_on_g_labels = tf.zeros_like(d_on_g_logits)\n",
        "\n",
        "        d_loss = tf.contrib.gan.losses.wargs.modified_discriminator_loss(\n",
        "            discriminator_real_outputs=d_on_data_logits,\n",
        "            discriminator_gen_outputs=d_on_g_logits,\n",
        "            reduction=tf.losses.Reduction.NONE,\n",
        "            label_smoothing=0.2\n",
        "        )\n",
        "\n",
        "        # Generator loss\n",
        "        g_loss = tf.contrib.gan.losses.wargs.modified_generator_loss(\n",
        "            discriminator_gen_outputs=d_on_g_logits,\n",
        "            reduction=tf.losses.Reduction.NONE\n",
        "        )\n",
        "\n",
        "        # TRAIN #\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            d_loss = tf.reduce_mean(d_loss)\n",
        "            g_loss = tf.reduce_mean(g_loss)\n",
        "            d_optimizer = tf.train.AdamOptimizer(learning_rate=D_LR, beta1=0.5)\n",
        "            g_optimizer = tf.train.AdamOptimizer(learning_rate=G_LR, beta1=0.5)\n",
        "\n",
        "            d_optimizer = tf.contrib.tpu.CrossShardOptimizer(d_optimizer)\n",
        "            g_optimizer = tf.contrib.tpu.CrossShardOptimizer(g_optimizer)\n",
        "\n",
        "            with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "                d_step = d_optimizer.minimize(d_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                                                                 scope='Discriminator'))\n",
        "                g_step = g_optimizer.minimize(g_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                                                                 scope='Generator'))\n",
        "\n",
        "                increment_step = tf.assign_add(tf.train.get_or_create_global_step(), 1)\n",
        "                joint_op = tf.group([d_step, g_step, increment_step])\n",
        "\n",
        "                return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=g_loss, train_op=joint_op)\n",
        "\n",
        "        # EVAL #\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "            def _eval_metric_fn(d_loss, g_loss, d_real_labels, d_gen_lanels, d_real_logits, d_gen_logits,\n",
        "                                real_images, generated_images):\n",
        "                return {\n",
        "                    'discriminator_loss': tf.metrics.mean(d_loss),\n",
        "                    'generator_loss': tf.metrics.mean(g_loss),\n",
        "                    'discriminator_real_accuracy': tf.metrics.accuracy(labels=d_real_labels, predictions=tf.math.round(tf.sigmoid(d_real_logits))),\n",
        "                    'discriminator_gen_accuracy': tf.metrics.accuracy(labels=d_gen_lanels, predictions=tf.math.round(tf.sigmoid(d_gen_logits))),\n",
        "                    'fid': calculate_fid(real_images, generated_images)\n",
        "                }\n",
        "\n",
        "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=tf.reduce_mean(g_loss),\n",
        "                                                   eval_metrics=(_eval_metric_fn, [d_loss, g_loss, d_on_data_labels,\n",
        "                                                                                   d_on_g_labels, d_on_data_logits, d_on_g_logits,\n",
        "                                                                                   real_images, generated_images]))\n",
        "\n",
        "    # Training\n",
        "    config = tf.contrib.tpu.RunConfig(\n",
        "        master=TF_MASTER,\n",
        "        save_checkpoints_steps=EVAL_EPOCHS,\n",
        "        save_checkpoints_secs=None,\n",
        "        save_summary_steps=EVAL_EPOCHS,\n",
        "        model_dir=MODEL_DIR,\n",
        "        keep_checkpoint_max=3,\n",
        "        tpu_config=tf.contrib.tpu.TPUConfig(iterations_per_loop=EVAL_EPOCHS))\n",
        "\n",
        "    # TPU-based estimator used for TRAIN and EVAL\n",
        "    est = tf.contrib.tpu.TPUEstimator(\n",
        "        model_fn=model_fn,\n",
        "        use_tpu=True,\n",
        "        config=config,\n",
        "        train_batch_size=BATCH_SIZE,\n",
        "        eval_batch_size=BATCH_SIZE)\n",
        "\n",
        "    # CPU-based estimator used for PREDICT (generating images)\n",
        "    cpu_est = tf.contrib.tpu.TPUEstimator(\n",
        "        model_fn=model_fn,\n",
        "        use_tpu=False,\n",
        "        config=config,\n",
        "        predict_batch_size=EXAMPLES)\n",
        "\n",
        "    current_step = estimator._load_global_step_from_checkpoint_dir(MODEL_DIR)\n",
        "    tf.logging.info('Starting training')\n",
        "\n",
        "    while current_step < EPOCHS:\n",
        "        next_checkpoint = int(min(current_step + EVAL_EPOCHS, EPOCHS))\n",
        "        est.train(input_fn=make_input_fn(), max_steps=next_checkpoint)\n",
        "        current_step = next_checkpoint\n",
        "        tf.logging.info('Finished training step %d' % current_step)\n",
        "\n",
        "        # Evaluation\n",
        "        metrics = est.evaluate(input_fn=make_input_fn(False), steps=1)\n",
        "        tf.logging.info('Finished evaluating')\n",
        "        tf.logging.info(metrics)\n",
        "\n",
        "        # Render some generated images\n",
        "        generated_iter = cpu_est.predict(input_fn=noise_input_fn)\n",
        "        images = [p['generated_images'] for p in generated_iter]\n",
        "        save_imgs(current_step, images)\n",
        "        tf.logging.info('Finished generating images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACYRgodbTMlv",
        "outputId": "a49ae7b9-c617-40c3-9a5f-b1ea9d3e96b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1506
        }
      },
      "source": [
        "CHANNELS = 4\n",
        "LATENT_DIM = 128\n",
        "ADD_NOISE_TO_EXAMPLE = True\n",
        "\n",
        "DROPOUT_PROB = 0.5\n",
        "ALPHA = 0.2\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 100000\n",
        "EVAL_EPOCHS = 5000\n",
        "data_file = 'gs://tputestingmnist/datasets/characters_front.tfrecords'\n",
        "\n",
        "G_LR = 0.0002\n",
        "\n",
        "for D_LR in [0.0001]:\n",
        "    for KERNEL_SIZE in [4]:\n",
        "        RUN_NAME = 'DCGAN_3_d{}_kernel{}'.format(D_LR, KERNEL_SIZE)\n",
        "        try:\n",
        "            do_experiment()\n",
        "        except Exception as e:\n",
        "            print (e)\n",
        "            pass\n",
        "        "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "WARNING:tensorflow:Estimator's model_fn (<function do_experiment.<locals>.model_fn at 0x7f20be5f19d8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://tputestingmnist/DCGAN_3_d0.0001_kernel4/', '_tf_random_seed': None, '_save_summary_steps': 5000, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f20b8bc4898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.67.58.242:8470', '_evaluation_master': 'grpc://10.67.58.242:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=5000, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:Estimator's model_fn (<function do_experiment.<locals>.model_fn at 0x7f20be5f19d8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://tputestingmnist/DCGAN_3_d0.0001_kernel4/', '_tf_random_seed': None, '_save_summary_steps': 5000, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f20b8bc47b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.67.58.242:8470', '_evaluation_master': 'grpc://10.67.58.242:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=5000, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:Starting training\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.67.58.242:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 4571375435776318477)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 16426617924268670681)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12246324947608673830)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5940735406376811683)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4645549996854251999)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14210986266966655512)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10131950523105587271)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13597571845762541188)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14555851999505906982)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 12346966395665754405)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 10084032373237521651)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name tpu_worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://tputestingmnist/DCGAN_3_d0.0001_kernel4/model.ckpt-60000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 60000 into gs://tputestingmnist/DCGAN_3_d0.0001_kernel4/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (5000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (5000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 65000 into gs://tputestingmnist/DCGAN_3_d0.0001_kernel4/model.ckpt.\n",
            "INFO:tensorflow:loss = 5.3915563, step = 65000\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 5.3915563.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "INFO:tensorflow:Finished training step 65000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "(1024, 48, 48, 4)\n",
            "(1024, 48, 48, 4)\n",
            "INFO:tensorflow:Error recorded from evaluation_loop: Index out of range using input dim 0; input has only 0 dims for 'strided_slice_4' (op: 'StridedSlice') with input shapes: [], [1], [1], [1] and with computed input tensors: input[3] = <1>.\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "WARNING:tensorflow:Reraising captured error\n",
            "Index out of range using input dim 0; input has only 0 dims for 'strided_slice_4' (op: 'StridedSlice') with input shapes: [], [1], [1], [1] and with computed input tensors: input[3] = <1>.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}