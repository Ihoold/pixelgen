{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pix2pix.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "display_name": "Python [conda env:tensorflow]",
      "language": "python",
      "name": "conda-env-tensorflow-py"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-KtZcaWB02O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from unittest import mock\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.estimator import estimator\n",
        "from tensorflow.python.training.basic_session_run_hooks import CheckpointSaverHook, meta_graph\n",
        "from tensorflow.python.platform import tf_logging as logging\n",
        "from google.colab import drive, auth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCzCaKLPB02f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################### SETUP #####################################\n",
        "\n",
        "def setup():\n",
        "    drive.mount('/content/gdrive')\n",
        "    auth.authenticate_user()\n",
        "\n",
        "\n",
        "def upload_credentials():\n",
        "    # Upload credentials to TPU.\n",
        "    with tf.Session(TF_MASTER) as sess:    \n",
        "        with open('/content/adc.json', 'r') as f:\n",
        "            auth_info = json.load(f)\n",
        "        tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ycJsJCB02o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################# DATA INPUT ###################################\n",
        "\n",
        "def parser(serialized_example):\n",
        "        \"\"\"Parses a single example into image and label tensors.\"\"\"\n",
        "        features = tf.parse_single_example(\n",
        "            serialized_example,\n",
        "            features={\n",
        "                'image_raw': tf.FixedLenFeature([], tf.string),\n",
        "                'image_transformed': tf.FixedLenFeature([], tf.string),\n",
        "                'label': tf.FixedLenFeature([], tf.int64)   # label is unused\n",
        "            })\n",
        "\n",
        "\n",
        "        result_image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
        "        result_image.set_shape([48 * 48 * 4])\n",
        "        result_image = tf.reshape(result_image, [48, 48, 4])[:,:,:CHANNELS]\n",
        "        # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
        "        result_image = tf.cast(result_image, dtype=tf.float32) / 127.5 - 1\n",
        "\n",
        "        input_image = tf.decode_raw(features['image_transformed'], tf.uint8)\n",
        "        input_image.set_shape([48 * 48 * 4])\n",
        "        input_image = tf.reshape(input_image, [48, 48, 4])[:,:,:CHANNELS]\n",
        "        # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
        "        input_image = tf.cast(input_image, dtype=tf.float32) / 127.5 - 1\n",
        "\n",
        "        return input_image, result_image\n",
        "\n",
        "\n",
        "def make_input_fn(is_training=True):\n",
        "    def input_fn(params):\n",
        "        batch_size = params['batch_size']\n",
        "        dataset = tf.data.TFRecordDataset(data_file).map(parser).cache().shuffle(batch_size)\n",
        "        if is_training:\n",
        "            dataset = dataset.repeat()\n",
        "        input_images, result_images = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
        "\n",
        "        if ADD_NOISE_TO_EXAMPLE:\n",
        "            input_images += tf.random_normal(shape=tf.shape(input_images), mean=0.0, stddev=0.1, dtype=tf.float32)\n",
        "\n",
        "        features = {\n",
        "            'image_input': input_images,\n",
        "            'image_result': result_images,\n",
        "            'random_noise': tf.random_uniform([params['batch_size'], 3, 3, LATENT_DIM // 9], -1, 1, dtype=tf.float32)\n",
        "        }\n",
        "        return features, None\n",
        "    return input_fn\n",
        "\n",
        "\n",
        "def predict_input_fn(params):\n",
        "    batch_size = params['batch_size']\n",
        "    dataset = tf.data.TFRecordDataset(data_file).map(parser).cache().shuffle(batch_size)\n",
        "    input_images, _ = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
        "    \n",
        "    noise_dataset = tf.data.Dataset.from_tensors(tf.constant(np.random.uniform(-1, 1, (params['batch_size'], 3, 3, LATENT_DIM // 9)), dtype=tf.float32))\n",
        "    return {\n",
        "        'image_input': input_images,\n",
        "        'random_noise': noise_dataset.make_one_shot_iterator().get_next()\n",
        "    }, None\n",
        "\n",
        "\n",
        "# margonem_data_file = 'gs://tputestingmnist/datasets/characters_margonem_conditional_7.tfrecords'\n",
        "# def margonem_predict_input_fn(params):\n",
        "#     batch_size = params['batch_size']\n",
        "#     dataset = tf.data.TFRecordDataset(margonem_data_file).map(parser).cache().shuffle(batch_size)\n",
        "#     input_images, _ = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
        "#     return {'image_input': input_images}, None\n",
        "\n",
        "\n",
        "# def noise_input_fn(params):  \n",
        "#     noise_dataset = tf.data.Dataset.from_tensors(tf.constant(np.random.uniform(-1, 1, (params['batch_size'], LATENT_DIM)), dtype=tf.float32))\n",
        "#     return {'random_noise': noise_dataset.make_one_shot_iterator().get_next()}, None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6i0DewZB02v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################### DATA SAVEING ###################################\n",
        " \n",
        "def images_to_zero_one(images):\n",
        "        return np.clip(np.array(images) * 0.5 + 0.5, 0., 1.)\n",
        "\n",
        "\n",
        "def save_imgs(epoch, images):\n",
        "    if not os.path.exists(GOOGLE_DRIVE_DIR):\n",
        "        os.mkdir(GOOGLE_DRIVE_DIR)\n",
        "\n",
        "    # Rescale images to 0 - 1\n",
        "    images = images_to_zero_one(images)\n",
        "    fig, axs = plt.subplots(R, C, figsize=(20,20))\n",
        "\n",
        "    for i in range(R):\n",
        "        for j in range(C):\n",
        "            axs[i,j].imshow(images[C*i + j])\n",
        "            axs[i,j].axis('off')\n",
        "\n",
        "    fig.savefig(os.path.join(GOOGLE_DRIVE_DIR, '{}.png'.format(epoch)))\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khVvoOzKB024",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################## MODEL #######################################\n",
        "\n",
        "def _leaky_relu(x):\n",
        "    return tf.nn.leaky_relu(x, alpha=ALPHA)\n",
        "\n",
        "\n",
        "def _relu(x):\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def _batch_norm(x, is_training, name):\n",
        "    return tf.layers.batch_normalization(x, momentum=0.8, epsilon=1e-5, \n",
        "                                         training=is_training, name=name)\n",
        "\n",
        "\n",
        "def _dense(x, neurons, name, activation=None):\n",
        "    return tf.layers.dense(x, neurons, name=name, activation=activation,\n",
        "                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "def _conv2d(x, filters, stride, name, activation=None):\n",
        "    return tf.layers.conv2d(x, filters, [KERNEL_SIZE, KERNEL_SIZE], \n",
        "                            strides=[stride, stride], activation=activation,\n",
        "                            padding='same', name=name,\n",
        "                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "def _deconv2d(x, filters, stride, name, activation=None):\n",
        "    return tf.layers.conv2d_transpose(x, filters, [KERNEL_SIZE, KERNEL_SIZE],\n",
        "                                      strides=[stride, stride], activation=activation,\n",
        "                                      padding='same', name=name,\n",
        "                                      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "def _dropout(x, name):\n",
        "    return tf.nn.dropout(x, rate=DROPOUT_PROB, name=name)\n",
        "\n",
        "\n",
        "def convolution_block(x, filters, resize_factor, is_training, index,\n",
        "                      activation=_leaky_relu, dropout=False, batch_norm=True):\n",
        "\n",
        "    x = _conv2d(x, filters=filters, stride=resize_factor, activation=activation, name='conv_{}'.format(index))\n",
        "    if batch_norm:\n",
        "        x = _batch_norm(x, is_training, name='bn_conv_{}'.format(index))\n",
        "    if dropout:\n",
        "        x = _dropout(x, name='drop_deconv_{}'.format(index))\n",
        "    return x\n",
        "\n",
        "\n",
        "def deconvolution_block(x, filters, resize_factor, is_training, index,\n",
        "                        activation=_relu, dropout=False, batch_norm=True):\n",
        "\n",
        "    x = _deconv2d(x, filters=filters, stride=resize_factor, activation=activation, name='deconv_{}'.format(index))\n",
        "    if batch_norm:\n",
        "        x = _batch_norm(x, is_training, name='bn_deconv_{}'.format(index))\n",
        "    if dropout:\n",
        "        x = _dropout(x, name='drop_deconv_{}'.format(index))\n",
        "    return x\n",
        "\n",
        "\n",
        "class Pix2Pix:\n",
        "\n",
        "    @staticmethod\n",
        "    def discriminator(x, is_training=True, scope='Discriminator'):\n",
        "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "            x = convolution_block(x, 64, 2, is_training, 11, batch_norm=False)\n",
        "            x = convolution_block(x, 128, 2, is_training, 12)\n",
        "            x = convolution_block(x, 256, 2, is_training, 13)\n",
        "            x = convolution_block(x, 512, 2, is_training, 14)\n",
        "            \n",
        "            x = tf.layers.Flatten()(x)\n",
        "            x = _dense(x, neurons=1, name='d_dense')\n",
        "\n",
        "            return x\n",
        "\n",
        "    @staticmethod\n",
        "    def generator(image, noise, is_training=True, scope='Generator'):\n",
        "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "            \n",
        "            x1 = convolution_block(image, 64, 2, is_training, 11, dropout=False, batch_norm=False)\n",
        "            x2 = convolution_block(x1, 128, 2, is_training, 12, dropout=False)\n",
        "            x3 = convolution_block(x2, 256, 2, is_training, 13, dropout=False)\n",
        "            x4 = convolution_block(x3, 512, 2, is_training, 14, dropout=False)\n",
        "\n",
        "            x5 = deconvolution_block(tf.concat([x4, noise], axis=3), 512, 2, is_training, 21)\n",
        "            x6 = deconvolution_block(tf.concat([x3, x5], axis=3), 256, 2, is_training, 22)\n",
        "            x7 = deconvolution_block(tf.concat([x2, x6], axis=3), 128, 2, is_training, 23)\n",
        "            x8 = deconvolution_block(tf.concat([x1, x7], axis=3), CHANNELS, 2, is_training, 24, activation=tf.tanh, batch_norm=False)\n",
        "\n",
        "            return x8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcr7UF8SB029",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################ MODEL FUN #####################################\n",
        "\n",
        "def make_model_fn(model):\n",
        "    def model_fn(features, labels, mode, params):\n",
        "        # PREDICT #\n",
        "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "            image_input = features['image_input']\n",
        "            noise = features['random_noise']\n",
        "            generated_images = model.generator(image_input, noise, is_training=False)\n",
        "            predictions = {'generated_images': generated_images, 'image_input': image_input}\n",
        "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "        image_result = features['image_result']\n",
        "        image_input = features['image_input']\n",
        "        noise = features['random_noise']\n",
        "        generated_images = model.generator(image_input, noise, is_training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
        "\n",
        "        # Discriminator loss\n",
        "        d_on_data_logits = tf.squeeze(model.discriminator(tf.concat([image_input, image_result], axis=3)))\n",
        "        d_on_data_labels = tf.ones_like(d_on_data_logits)\n",
        "\n",
        "        d_on_g_logits = tf.squeeze(model.discriminator(tf.concat([image_input, generated_images], axis=3)))\n",
        "        d_on_g_labels = tf.zeros_like(d_on_g_logits)\n",
        "\n",
        "        d_loss = tf.contrib.gan.losses.wargs.modified_discriminator_loss(\n",
        "            discriminator_real_outputs=d_on_data_logits,\n",
        "            discriminator_gen_outputs=d_on_g_logits,\n",
        "            reduction=tf.losses.Reduction.NONE,\n",
        "            label_smoothing=0.2\n",
        "        )\n",
        "\n",
        "        # Generator loss\n",
        "        g_loss = tf.contrib.gan.losses.wargs.modified_generator_loss(\n",
        "            discriminator_gen_outputs=d_on_g_logits,\n",
        "            reduction=tf.losses.Reduction.NONE\n",
        "        )\n",
        "\n",
        "        # TRAIN #\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            d_loss = tf.reduce_mean(d_loss)\n",
        "            g_loss = tf.reduce_mean(g_loss)\n",
        "            d_optimizer = tf.train.AdamOptimizer(learning_rate=D_LR, beta1=0.5)\n",
        "            g_optimizer = tf.train.AdamOptimizer(learning_rate=G_LR, beta1=0.5)\n",
        "\n",
        "            d_optimizer = tf.contrib.tpu.CrossShardOptimizer(d_optimizer)\n",
        "            g_optimizer = tf.contrib.tpu.CrossShardOptimizer(g_optimizer)\n",
        "\n",
        "            with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "                d_step = d_optimizer.minimize(d_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                                                                 scope='Discriminator'))\n",
        "                g_step = g_optimizer.minimize(g_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                                                                 scope='Generator'))\n",
        "\n",
        "                increment_step = tf.assign_add(tf.train.get_or_create_global_step(), 1)\n",
        "                joint_op = tf.group([d_step, g_step, increment_step])\n",
        "\n",
        "                return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=g_loss, train_op=joint_op)\n",
        "\n",
        "        # EVAL #\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "            def _eval_metric_fn(d_loss, g_loss, d_real_labels, d_gen_lanels, d_real_logits, d_gen_logits):\n",
        "                return {\n",
        "                    'discriminator_loss': tf.metrics.mean(d_loss),\n",
        "                    'generator_loss': tf.metrics.mean(g_loss),\n",
        "                    'discriminator_real_accuracy': tf.metrics.accuracy(labels=d_real_labels, predictions=tf.math.round(tf.sigmoid(d_real_logits))),\n",
        "                    'discriminator_gen_accuracy': tf.metrics.accuracy(labels=d_gen_lanels, predictions=tf.math.round(tf.sigmoid(d_gen_logits))),\n",
        "                }\n",
        "\n",
        "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=tf.reduce_mean(g_loss),\n",
        "                                                   eval_metrics=(_eval_metric_fn, [d_loss, g_loss, d_on_data_labels,\n",
        "                                                                                   d_on_g_labels, d_on_data_logits, d_on_g_logits]))\n",
        "    return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5rb586jB03F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################ ESTIMATORS ####################################\n",
        "\n",
        "def make_estimators(model, only_cpu=False):\n",
        "    model_fn = make_model_fn(model)\n",
        "    \n",
        "    config = tf.contrib.tpu.RunConfig(\n",
        "        master=TF_MASTER,\n",
        "        save_checkpoints_steps=EVAL_EPOCHS,\n",
        "        save_checkpoints_secs=None,\n",
        "        save_summary_steps=EVAL_EPOCHS,\n",
        "        model_dir=MODEL_DIR,\n",
        "        keep_checkpoint_max=3,\n",
        "        tpu_config=tf.contrib.tpu.TPUConfig(iterations_per_loop=EVAL_EPOCHS))\n",
        "\n",
        "    if not only_cpu:\n",
        "        # TPU-based estimator used for TRAIN and EVAL\n",
        "        est = tf.contrib.tpu.TPUEstimator(\n",
        "            model_fn=model_fn,\n",
        "            use_tpu=True,\n",
        "            config=config,\n",
        "            train_batch_size=BATCH_SIZE,\n",
        "            eval_batch_size=BATCH_SIZE)\n",
        "    else:\n",
        "        est = None\n",
        "\n",
        "    # CPU-based estimator used for PREDICT (generating images)\n",
        "    cpu_est = tf.contrib.tpu.TPUEstimator(\n",
        "        model_fn=model_fn,\n",
        "        use_tpu=False,\n",
        "        config=config,\n",
        "        predict_batch_size=EXAMPLES)\n",
        "    \n",
        "    return est, cpu_est"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nIuQqdWB03O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################# TRAINING #####################################\n",
        "\n",
        "def train(est, cpu_est):\n",
        "    current_step = estimator._load_global_step_from_checkpoint_dir(MODEL_DIR)\n",
        "    tf.logging.info('Starting training')\n",
        "\n",
        "    while current_step < EPOCHS:\n",
        "        next_checkpoint = int(min(current_step + EVAL_EPOCHS, EPOCHS))\n",
        "        est.train(input_fn=make_input_fn(), max_steps=next_checkpoint)\n",
        "        current_step = next_checkpoint\n",
        "        tf.logging.info('Finished training step %d' % current_step)\n",
        "\n",
        "        # Evaluation\n",
        "        metrics = est.evaluate(input_fn=make_input_fn(False), steps=1)\n",
        "        tf.logging.info('Finished evaluating')\n",
        "        tf.logging.info(metrics)\n",
        "\n",
        "        # Render some generated images\n",
        "        generated_iter = cpu_est.predict(input_fn=predict_input_fn)\n",
        "        images = [np.concatenate([p['image_input'], p['generated_images']], axis=1) for p in generated_iter]\n",
        "        save_imgs(step, images)\n",
        "        tf.logging.info('Finished generating images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STjYktznB03T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_experiment():\n",
        "    setup()\n",
        "    upload_credentials()\n",
        "    model = Pix2Pix()\n",
        "    est, cpu_est = make_estimators(model)\n",
        "    train(est, cpu_est)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS5ajICgBpCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_on_image(image, cpu_est):\n",
        "\n",
        "    def image_predict_input_fn(params):\n",
        "        batch_size = params['batch_size']\n",
        "        images = np.zeros((batch_size, 48, 48, 4), dtype=np.float32)\n",
        "        images[0,:,:,:] = (image - 0.5) * 2\n",
        "        dataset = tf.data.Dataset.from_tensors(images)\n",
        "        input_images = dataset.make_one_shot_iterator().get_next()    \n",
        "        noise_dataset = tf.data.Dataset.from_tensors(tf.constant(np.ones((params['batch_size'], 3, 3, LATENT_DIM // 9)), dtype=tf.float32))\n",
        "        \n",
        "        return {'image_input': input_images, 'random_noise': noise_dataset.make_one_shot_iterator().get_next()}, None\n",
        "\n",
        "    generated_iter = cpu_est.predict(input_fn=image_predict_input_fn)\n",
        "    images = [np.concatenate([p['image_input'], p['generated_images']], axis=1) for p in generated_iter]\n",
        "    plt.imshow(images_to_zero_one(images)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8nJTGZfCI5h",
        "colab_type": "code",
        "outputId": "52df1e27-7dc6-4abd-b680-883e3669d9f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "setup()\n",
        "upload_credentials()\n",
        "model = Pix2Pix()\n",
        "_, cpu_est = make_estimators(model, only_cpu=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:Estimator's model_fn (<function make_model_fn.<locals>.model_fn at 0x7f8f974f7ae8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://tputestingmnist/Pix2Pix_3/', '_tf_random_seed': None, '_save_summary_steps': 5000, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8fa68b0ac8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.126.241.178:8470', '_evaluation_master': 'grpc://10.126.241.178:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=5000, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDvqThn2CPjf",
        "colab_type": "code",
        "outputId": "498219c9-e780-489f-c7a5-d12eba6c1da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "image = plt.imread('Dad.png')\n",
        "predict_on_image(image[0:48, 48:96, :], cpu_est)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://tputestingmnist/Pix2Pix_3/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADKCAYAAAC11LviAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEP4fres7rlmMJ7cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vdQ83GWB03c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "R, C = 4, 4\n",
        "EXAMPLES = R * C\n",
        "    \n",
        "CHANNELS = 4\n",
        "LATENT_DIM = 128\n",
        "ADD_NOISE_TO_EXAMPLE = False\n",
        "\n",
        "DROPOUT_PROB = 0.5\n",
        "ALPHA = 0.2\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 40000\n",
        "EVAL_EPOCHS = 5000\n",
        "G_LR = 0.0002\n",
        "D_LR = 0.0001\n",
        "KERNEL_SIZE = 4\n",
        "\n",
        "RUN_NAME = 'Pix2Pix_3'\n",
        "\n",
        "margonem_data_file = 'gs://tputestingmnist/datasets/characters_margonem_conditional_7.tfrecords'\n",
        "data_file = 'gs://tputestingmnist/datasets/characters_conditional_7.tfrecords'\n",
        "MODEL_DIR = 'gs://tputestingmnist/{}/'.format(RUN_NAME)\n",
        "GOOGLE_DRIVE_DIR = '/content/gdrive/My Drive/Programowanie/PixelGen/{}'.format(RUN_NAME)\n",
        "TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "# try:\n",
        "#     do_experiment()\n",
        "# except Exception as e:\n",
        "#     print (e)\n",
        "#     pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eImay3kpN2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}