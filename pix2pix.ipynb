{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pix2pix.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "display_name": "Python [conda env:tensorflow]",
      "language": "python",
      "name": "conda-env-tensorflow-py"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-KtZcaWB02O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from unittest import mock\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.estimator import estimator\n",
        "from tensorflow.python.training.basic_session_run_hooks import CheckpointSaverHook, meta_graph\n",
        "from tensorflow.python.platform import tf_logging as logging\n",
        "from google.colab import drive, auth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCzCaKLPB02f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################### SETUP #####################################\n",
        "\n",
        "def setup():\n",
        "    drive.mount('/content/gdrive')\n",
        "    auth.authenticate_user()\n",
        "\n",
        "\n",
        "def upload_credentials():\n",
        "    # Upload credentials to TPU.\n",
        "    with tf.Session(TF_MASTER) as sess:    \n",
        "        with open('/content/adc.json', 'r') as f:\n",
        "            auth_info = json.load(f)\n",
        "        tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ycJsJCB02o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################# DATA INPUT ###################################\n",
        "\n",
        "def parser(serialized_example):\n",
        "        \"\"\"Parses a single example into image and label tensors.\"\"\"\n",
        "        features = tf.parse_single_example(\n",
        "            serialized_example,\n",
        "            features={\n",
        "                'image_raw': tf.FixedLenFeature([], tf.string),\n",
        "                'image_transformed': tf.FixedLenFeature([], tf.string),\n",
        "                'label': tf.FixedLenFeature([], tf.int64)   # label is unused\n",
        "            })\n",
        "\n",
        "\n",
        "        result_image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
        "        result_image.set_shape([48 * 48 * 4])\n",
        "        result_image = tf.reshape(result_image, [48, 48, 4])[:,:,:CHANNELS]\n",
        "        # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
        "        result_image = tf.cast(result_image, dtype=tf.float32) / 127.5 - 1\n",
        "\n",
        "        input_image = tf.decode_raw(features['image_transformed'], tf.uint8)\n",
        "        input_image.set_shape([48 * 48 * 4])\n",
        "        input_image = tf.reshape(input_image, [48, 48, 4])[:,:,:CHANNELS]\n",
        "        # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
        "        input_image = tf.cast(input_image, dtype=tf.float32) / 127.5 - 1\n",
        "\n",
        "        return input_image, result_image\n",
        "\n",
        "\n",
        "def make_input_fn(is_training=True):\n",
        "    def input_fn(params):\n",
        "        batch_size = params['batch_size']\n",
        "        dataset = tf.data.TFRecordDataset(data_file).map(parser).cache().shuffle(batch_size)\n",
        "        if is_training:\n",
        "            dataset = dataset.repeat()\n",
        "        input_images, result_images = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
        "\n",
        "        if ADD_NOISE_TO_EXAMPLE:\n",
        "            input_images += tf.random_normal(shape=tf.shape(input_images), mean=0.0, stddev=0.1, dtype=tf.float32)\n",
        "\n",
        "        features = {\n",
        "            'image_input': input_images,\n",
        "            'image_result': result_images,\n",
        "        }\n",
        "        return features, None\n",
        "    return input_fn\n",
        "\n",
        "\n",
        "def predict_input_fn(params):\n",
        "    batch_size = params['batch_size']\n",
        "    dataset = tf.data.TFRecordDataset(data_file).map(parser).cache().shuffle(batch_size)\n",
        "    input_images, _ = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
        "    return {'image_input': input_images}, None\n",
        "\n",
        "\n",
        "margonem_data_file = 'gs://tputestingmnist/datasets/characters_margonem_conditional_7.tfrecords'\n",
        "def margonem_predict_input_fn(params):\n",
        "    batch_size = params['batch_size']\n",
        "    dataset = tf.data.TFRecordDataset(margonem_data_file).map(parser).cache().shuffle(batch_size)\n",
        "    input_images, _ = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
        "    return {'image_input': input_images}, None\n",
        "\n",
        "\n",
        "# def noise_input_fn(params):  \n",
        "#     noise_dataset = tf.data.Dataset.from_tensors(tf.constant(np.random.uniform(-1, 1, (params['batch_size'], LATENT_DIM)), dtype=tf.float32))\n",
        "#     return {'random_noise': noise_dataset.make_one_shot_iterator().get_next()}, None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6i0DewZB02v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################### DATA SAVEING ###################################\n",
        " \n",
        "def images_to_zero_one(images):\n",
        "        return np.clip(np.array(images) * 0.5 + 0.5, 0., 1.)\n",
        "\n",
        "\n",
        "def save_imgs(epoch, images):\n",
        "    if not os.path.exists(GOOGLE_DRIVE_DIR):\n",
        "        os.mkdir(GOOGLE_DRIVE_DIR)\n",
        "\n",
        "    # Rescale images to 0 - 1\n",
        "    images = images_to_zero_one(images)\n",
        "    fig, axs = plt.subplots(R, C, figsize=(20,20))\n",
        "\n",
        "    for i in range(R):\n",
        "        for j in range(C):\n",
        "            axs[i,j].imshow(images[C*i + j])\n",
        "            axs[i,j].axis('off')\n",
        "\n",
        "    fig.savefig(os.path.join(GOOGLE_DRIVE_DIR, '{}.png'.format(epoch)))\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khVvoOzKB024",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################## MODEL #######################################\n",
        "\n",
        "def _leaky_relu(x):\n",
        "    return tf.nn.leaky_relu(x, alpha=ALPHA)\n",
        "\n",
        "\n",
        "def _relu(x):\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def _batch_norm(x, is_training, name):\n",
        "    return tf.layers.batch_normalization(x, momentum=0.8, epsilon=1e-5, \n",
        "                                         training=is_training, name=name)\n",
        "\n",
        "\n",
        "def _dense(x, neurons, name, activation=None):\n",
        "    return tf.layers.dense(x, neurons, name=name, activation=activation,\n",
        "                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "def _conv2d(x, filters, stride, name, activation=None):\n",
        "    return tf.layers.conv2d(x, filters, [KERNEL_SIZE, KERNEL_SIZE], \n",
        "                            strides=[stride, stride], activation=activation,\n",
        "                            padding='same', name=name,\n",
        "                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "def _deconv2d(x, filters, stride, name, activation=None):\n",
        "    return tf.layers.conv2d_transpose(x, filters, [KERNEL_SIZE, KERNEL_SIZE],\n",
        "                                      strides=[stride, stride], activation=activation,\n",
        "                                      padding='same', name=name,\n",
        "                                      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "def _dropout(x, name):\n",
        "    return tf.nn.dropout(x, rate=DROPOUT_PROB, name=name)\n",
        "\n",
        "\n",
        "def convolution_block(x, filters, resize_factor, is_training, index,\n",
        "                      activation=_leaky_relu, dropout=False, batch_norm=True):\n",
        "\n",
        "    x = _conv2d(x, filters=filters, stride=resize_factor, activation=activation, name='conv_{}'.format(index))\n",
        "    if batch_norm:\n",
        "        x = _batch_norm(x, is_training, name='bn_conv_{}'.format(index))\n",
        "    if dropout:\n",
        "        x = _dropout(x, name='drop_deconv_{}'.format(index))\n",
        "    return x\n",
        "\n",
        "\n",
        "def deconvolution_block(x, filters, resize_factor, is_training, index,\n",
        "                        activation=_relu, dropout=False, batch_norm=True):\n",
        "\n",
        "    x = _deconv2d(x, filters=filters, stride=resize_factor, activation=activation, name='deconv_{}'.format(index))\n",
        "    if batch_norm:\n",
        "        x = _batch_norm(x, is_training, name='bn_deconv_{}'.format(index))\n",
        "    if dropout:\n",
        "        x = _dropout(x, name='drop_deconv_{}'.format(index))\n",
        "    return x\n",
        "\n",
        "\n",
        "class Pix2Pix:\n",
        "\n",
        "    @staticmethod\n",
        "    def discriminator(x, is_training=True, scope='Discriminator'):\n",
        "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "            x = convolution_block(x, 64, 2, is_training, 11, batch_norm=False)\n",
        "            x = convolution_block(x, 128, 2, is_training, 12)\n",
        "            x = convolution_block(x, 256, 2, is_training, 13)\n",
        "            x = convolution_block(x, 512, 2, is_training, 14)\n",
        "            \n",
        "            x = tf.layers.Flatten()(x)\n",
        "            x = _dense(x, neurons=1, name='d_dense')\n",
        "\n",
        "            return x\n",
        "\n",
        "    @staticmethod\n",
        "    def generator(image, is_training=True, scope='Generator'):\n",
        "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "            \n",
        "            x1 = convolution_block(image, 64, 2, is_training, 11, dropout=False, batch_norm=False)\n",
        "            x2 = convolution_block(x1, 128, 2, is_training, 12, dropout=False)\n",
        "            x3 = convolution_block(x2, 256, 2, is_training, 13, dropout=False)\n",
        "            x4 = convolution_block(x3, 512, 2, is_training, 14, dropout=False)\n",
        "\n",
        "            x5 = deconvolution_block(x4, 512, 2, is_training, 21)\n",
        "            x6 = deconvolution_block(tf.concat([x3, x5], axis=3), 256, 2, is_training, 22)\n",
        "            x7 = deconvolution_block(tf.concat([x2, x6], axis=3), 128, 2, is_training, 23)\n",
        "            x8 = deconvolution_block(tf.concat([x1, x7], axis=3), CHANNELS, 2, is_training, 24, activation=tf.tanh, batch_norm=False)\n",
        "\n",
        "            return x8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcr7UF8SB029",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################ MODEL FUN #####################################\n",
        "\n",
        "def make_model_fn(model):\n",
        "    def model_fn(features, labels, mode, params):\n",
        "        # PREDICT #\n",
        "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "            image_input = features['image_input']\n",
        "            generated_images = model.generator(image_input, is_training=False)\n",
        "            predictions = {'generated_images': generated_images, 'image_input': image_input}\n",
        "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "        image_result = features['image_result']\n",
        "        image_input = features['image_input']\n",
        "        generated_images = model.generator(image_input, is_training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
        "\n",
        "        # Discriminator loss\n",
        "        d_on_data_logits = tf.squeeze(model.discriminator(tf.concat([image_input, image_result], axis=3)))\n",
        "        d_on_data_labels = tf.ones_like(d_on_data_logits)\n",
        "\n",
        "        d_on_g_logits = tf.squeeze(model.discriminator(tf.concat([image_input, generated_images], axis=3)))\n",
        "        d_on_g_labels = tf.zeros_like(d_on_g_logits)\n",
        "\n",
        "        d_loss = tf.contrib.gan.losses.wargs.modified_discriminator_loss(\n",
        "            discriminator_real_outputs=d_on_data_logits,\n",
        "            discriminator_gen_outputs=d_on_g_logits,\n",
        "            reduction=tf.losses.Reduction.NONE,\n",
        "            label_smoothing=0.2\n",
        "        )\n",
        "\n",
        "        # Generator loss\n",
        "        g_loss = tf.contrib.gan.losses.wargs.modified_generator_loss(\n",
        "            discriminator_gen_outputs=d_on_g_logits,\n",
        "            reduction=tf.losses.Reduction.NONE\n",
        "        )\n",
        "\n",
        "        # TRAIN #\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            d_loss = tf.reduce_mean(d_loss)\n",
        "            g_loss = tf.reduce_mean(g_loss)\n",
        "            d_optimizer = tf.train.AdamOptimizer(learning_rate=D_LR, beta1=0.5)\n",
        "            g_optimizer = tf.train.AdamOptimizer(learning_rate=G_LR, beta1=0.5)\n",
        "\n",
        "            d_optimizer = tf.contrib.tpu.CrossShardOptimizer(d_optimizer)\n",
        "            g_optimizer = tf.contrib.tpu.CrossShardOptimizer(g_optimizer)\n",
        "\n",
        "            with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "                d_step = d_optimizer.minimize(d_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                                                                 scope='Discriminator'))\n",
        "                g_step = g_optimizer.minimize(g_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                                                                 scope='Generator'))\n",
        "\n",
        "                increment_step = tf.assign_add(tf.train.get_or_create_global_step(), 1)\n",
        "                joint_op = tf.group([d_step, g_step, increment_step])\n",
        "\n",
        "                return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=g_loss, train_op=joint_op)\n",
        "\n",
        "        # EVAL #\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "            def _eval_metric_fn(d_loss, g_loss, d_real_labels, d_gen_lanels, d_real_logits, d_gen_logits):\n",
        "                return {\n",
        "                    'discriminator_loss': tf.metrics.mean(d_loss),\n",
        "                    'generator_loss': tf.metrics.mean(g_loss),\n",
        "                    'discriminator_real_accuracy': tf.metrics.accuracy(labels=d_real_labels, predictions=tf.math.round(tf.sigmoid(d_real_logits))),\n",
        "                    'discriminator_gen_accuracy': tf.metrics.accuracy(labels=d_gen_lanels, predictions=tf.math.round(tf.sigmoid(d_gen_logits))),\n",
        "                }\n",
        "\n",
        "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=tf.reduce_mean(g_loss),\n",
        "                                                   eval_metrics=(_eval_metric_fn, [d_loss, g_loss, d_on_data_labels,\n",
        "                                                                                   d_on_g_labels, d_on_data_logits, d_on_g_logits]))\n",
        "    return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5rb586jB03F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################ ESTIMATORS ####################################\n",
        "\n",
        "def make_estimators(model, only_cpu=False):\n",
        "    model_fn = make_model_fn(model)\n",
        "    \n",
        "    config = tf.contrib.tpu.RunConfig(\n",
        "        master=TF_MASTER,\n",
        "        save_checkpoints_steps=EVAL_EPOCHS,\n",
        "        save_checkpoints_secs=None,\n",
        "        save_summary_steps=EVAL_EPOCHS,\n",
        "        model_dir=MODEL_DIR,\n",
        "        keep_checkpoint_max=3,\n",
        "        tpu_config=tf.contrib.tpu.TPUConfig(iterations_per_loop=EVAL_EPOCHS))\n",
        "\n",
        "    if not only_cpu:\n",
        "        # TPU-based estimator used for TRAIN and EVAL\n",
        "        est = tf.contrib.tpu.TPUEstimator(\n",
        "            model_fn=model_fn,\n",
        "            use_tpu=True,\n",
        "            config=config,\n",
        "            train_batch_size=BATCH_SIZE,\n",
        "            eval_batch_size=BATCH_SIZE)\n",
        "    else:\n",
        "        est = None\n",
        "\n",
        "    # CPU-based estimator used for PREDICT (generating images)\n",
        "    cpu_est = tf.contrib.tpu.TPUEstimator(\n",
        "        model_fn=model_fn,\n",
        "        use_tpu=False,\n",
        "        config=config,\n",
        "        predict_batch_size=EXAMPLES)\n",
        "    \n",
        "    return est, cpu_est"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nIuQqdWB03O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################# TRAINING #####################################\n",
        "\n",
        "def train(est, cpu_est):\n",
        "    current_step = estimator._load_global_step_from_checkpoint_dir(MODEL_DIR)\n",
        "    tf.logging.info('Starting training')\n",
        "\n",
        "    while current_step < EPOCHS:\n",
        "        next_checkpoint = int(min(current_step + EVAL_EPOCHS, EPOCHS))\n",
        "        est.train(input_fn=make_input_fn(), max_steps=next_checkpoint)\n",
        "        current_step = next_checkpoint\n",
        "        tf.logging.info('Finished training step %d' % current_step)\n",
        "\n",
        "        # Evaluation\n",
        "        metrics = est.evaluate(input_fn=make_input_fn(False), steps=1)\n",
        "        tf.logging.info('Finished evaluating')\n",
        "        tf.logging.info(metrics)\n",
        "\n",
        "    # Render some generated images\n",
        "    generated_iter = cpu_est.predict(input_fn=predict_input_fn)\n",
        "    images = [np.concatenate([p['image_input'], p['generated_images']], axis=1) for p in generated_iter]\n",
        "    save_imgs('pppp', images)\n",
        "    tf.logging.info('Finished generating images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STjYktznB03T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_experiment():\n",
        "    setup()\n",
        "    upload_credentials()\n",
        "    model = Pix2Pix()\n",
        "    est, cpu_est = make_estimators(model)\n",
        "    train(est, cpu_est)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS5ajICgBpCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_on_image(image, cpu_est):\n",
        "\n",
        "    def image_predict_input_fn(params):\n",
        "        batch_size = params['batch_size']\n",
        "        images = np.zeros((batch_size, 48, 48, 4), dtype=np.float32)\n",
        "        images[0,:,:,:] = (image - 0.5) * 2\n",
        "        dataset = tf.data.Dataset.from_tensors(images)\n",
        "        input_images = dataset.make_one_shot_iterator().get_next()\n",
        "        return {'image_input': input_images}, None\n",
        "\n",
        "    generated_iter = cpu_est.predict(input_fn=image_predict_input_fn)\n",
        "    images = [np.concatenate([p['image_input'], p['generated_images']], axis=1) for p in generated_iter]\n",
        "    plt.imshow(images_to_zero_one(images)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8nJTGZfCI5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "090023cc-8078-4248-d5f1-885ba12fc848"
      },
      "source": [
        "setup()\n",
        "upload_credentials()\n",
        "model = Pix2Pix()\n",
        "_, cpu_est = make_estimators(model, only_cpu=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "WARNING:tensorflow:Estimator's model_fn (<function make_model_fn.<locals>.model_fn at 0x7fd681c4a0d0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://tputestingmnist/Pix2Pix_2/', '_tf_random_seed': None, '_save_summary_steps': 5000, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd681d0d390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.33.129.154:8470', '_evaluation_master': 'grpc://10.33.129.154:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=5000, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDvqThn2CPjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "826c773c-8c43-4edb-844c-ec794197969a"
      },
      "source": [
        "image = plt.imread('1_yellow_blue.png')\n",
        "predict_on_image(image[0:48, 48:96, :], cpu_est)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://tputestingmnist/Pix2Pix_2/model.ckpt-40000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADKCAYAAAC11LviAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vdQ83GWB03c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2847
        },
        "outputId": "0e5dce1e-7cd9-4775-872e-400aec555e9b"
      },
      "source": [
        "R, C = 4, 4\n",
        "EXAMPLES = R * C\n",
        "    \n",
        "CHANNELS = 4\n",
        "LATENT_DIM = 128\n",
        "ADD_NOISE_TO_EXAMPLE = False\n",
        "\n",
        "DROPOUT_PROB = 0.5\n",
        "ALPHA = 0.2\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 40000\n",
        "EVAL_EPOCHS = 5000\n",
        "G_LR = 0.0002\n",
        "D_LR = 0.0001\n",
        "KERNEL_SIZE = 4\n",
        "\n",
        "RUN_NAME = 'Pix2Pix_2'\n",
        "\n",
        "margonem_data_file = 'gs://tputestingmnist/datasets/characters_margonem_conditional_7.tfrecords'\n",
        "data_file = 'gs://tputestingmnist/datasets/characters_conditional_7.tfrecords'\n",
        "MODEL_DIR = 'gs://tputestingmnist/{}/'.format(RUN_NAME)\n",
        "GOOGLE_DRIVE_DIR = '/content/gdrive/My Drive/Programowanie/PixelGen/{}'.format(RUN_NAME)\n",
        "TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "try:\n",
        "    do_experiment()\n",
        "except Exception as e:\n",
        "    print (e)\n",
        "    pass"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:Estimator's model_fn (<function make_model_fn.<locals>.model_fn at 0x7fd68264bd08>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://tputestingmnist/Pix2Pix_2/', '_tf_random_seed': None, '_save_summary_steps': 5000, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd6919c8c18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.33.129.154:8470', '_evaluation_master': 'grpc://10.33.129.154:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=5000, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:Estimator's model_fn (<function make_model_fn.<locals>.model_fn at 0x7fd68264bd08>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://tputestingmnist/Pix2Pix_2/', '_tf_random_seed': None, '_save_summary_steps': 5000, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd6919c8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.33.129.154:8470', '_evaluation_master': 'grpc://10.33.129.154:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=5000, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:Starting training\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.33.129.154:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 16008268262087318514)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5628165655485261412)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 15414583015657380486)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17499552080155448936)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 16692700328391843553)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 10030611701671685046)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9770227618302237831)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10379329601689372424)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10630314010980304989)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6570230510350745855)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 5923939283524437883)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From <ipython-input-6-a39348d312c3>:24: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "WARNING:tensorflow:From <ipython-input-6-a39348d312c3>:12: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.batch_normalization instead.\n",
            "WARNING:tensorflow:From <ipython-input-6-a39348d312c3>:31: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d_transpose instead.\n",
            "WARNING:tensorflow:From <ipython-input-6-a39348d312c3>:17: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name tpu_worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gs://tputestingmnist/Pix2Pix_2/model.ckpt-35000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 35000 into gs://tputestingmnist/Pix2Pix_2/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 3 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (5000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (5000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 40000 into gs://tputestingmnist/Pix2Pix_2/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:loss = 4.38934, step = 40000\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 4.38934.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "INFO:tensorflow:Finished training step 40000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py:2655: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-06-02T22:44:17Z\n",
            "INFO:tensorflow:TPU job name tpu_worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://tputestingmnist/Pix2Pix_2/model.ckpt-40000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Evaluation [1/1]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2019-06-02-22:44:30\n",
            "INFO:tensorflow:Saving dict for global step 40000: discriminator_gen_accuracy = 1.0, discriminator_loss = 0.74662066, discriminator_real_accuracy = 0.875, generator_loss = 4.322368, global_step = 40000, loss = 4.3435926\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: gs://tputestingmnist/Pix2Pix_2/model.ckpt-40000\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "INFO:tensorflow:Finished evaluating\n",
            "INFO:tensorflow:{'discriminator_gen_accuracy': 1.0, 'discriminator_loss': 0.74662066, 'discriminator_real_accuracy': 0.875, 'generator_loss': 4.322368, 'loss': 4.3435926, 'global_step': 40000}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://tputestingmnist/Pix2Pix_2/model.ckpt-40000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:Finished generating images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eImay3kpN2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}