{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "funit.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ihoold/pixelgen/blob/master/funit4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-KtZcaWB02O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.estimator import estimator\n",
        "from google.colab import drive, auth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi4fxG6GVo7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "R, C = 4, 3\n",
        "EXAMPLES = R * C\n",
        "CHANNELS = 4\n",
        "\n",
        "ALPHA = 0.2\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 20000\n",
        "EVAL_EPOCHS = 1000\n",
        "G_LR = 0.0002\n",
        "D_LR = 0.0001\n",
        "LR_REC = 0.1\n",
        "LR_FEAT = 1\n",
        "KERNEL_SIZE = 4\n",
        "NUM_CLASSES = 21\n",
        "\n",
        "MODEL_NAME = 'FUNIT'\n",
        "RUN_NAME = 'FUNIT_only_gen_42'\n",
        "\n",
        "data_train_file = 'gs://tputestingmnist/datasets/dataset_train_funit.tfrecords'\n",
        "data_test_file = 'gs://tputestingmnist/datasets/dataset_test_funit.tfrecords'\n",
        "MODEL_DIR = 'gs://tputestingmnist/{}/{}/'.format(MODEL_NAME, RUN_NAME)\n",
        "GOOGLE_DRIVE_DIR = '/content/gdrive/My Drive/Programowanie/PixelGen/{}'.format(RUN_NAME)\n",
        "TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCzCaKLPB02f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################### SETUP #####################################\n",
        "\n",
        "def setup():\n",
        "    drive.mount('/content/gdrive')\n",
        "    auth.authenticate_user()\n",
        "\n",
        "\n",
        "def upload_credentials():\n",
        "    # Upload credentials to TPU.\n",
        "    with tf.Session(TF_MASTER) as sess:    \n",
        "        with open('/content/adc.json', 'r') as f:\n",
        "            auth_info = json.load(f)\n",
        "        tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ycJsJCB02o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################# DATA INPUT ###################################\n",
        "\n",
        "def parser(serialized_example):\n",
        "        \"\"\"Parses a single example into image and label tensors.\"\"\"\n",
        "        features = tf.parse_single_example(\n",
        "            serialized_example,\n",
        "            features={\n",
        "                'image_content': tf.FixedLenFeature([], tf.string),\n",
        "                'image_style': tf.FixedLenFeature([], tf.string),\n",
        "                'label': tf.FixedLenFeature([], tf.int64) \n",
        "            })\n",
        "\n",
        "        content_image = tf.decode_raw(features['image_content'], tf.uint8)\n",
        "        content_image.set_shape([48 * 48 * 4])\n",
        "        content_image = tf.reshape(content_image, [48, 48, 4])[:,:,:CHANNELS]\n",
        "        # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
        "        content_image = tf.cast(content_image, dtype=tf.float32) / 127.5 - 1\n",
        "\n",
        "        style_image = tf.decode_raw(features['image_style'], tf.uint8)\n",
        "        style_image.set_shape([48 * 48 * 4])\n",
        "        style_image = tf.reshape(style_image, [48, 48, 4])[:,:,:CHANNELS]\n",
        "        # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
        "        style_image = tf.cast(style_image, dtype=tf.float32) / 127.5 - 1\n",
        "        \n",
        "        label = features['label']\n",
        "\n",
        "        return {'style_images': style_image, 'content_images': content_image}, label\n",
        "\n",
        "\n",
        "def make_input_fn(is_training=True, one_batch=False):\n",
        "    def input_fn(params):\n",
        "        batch_size = params['batch_size']\n",
        "        dataset = tf.data.TFRecordDataset(data_train_file, buffer_size=8*1024*1024)\n",
        "        dataset = dataset.map(parser).cache().shuffle(batch_size)\n",
        "        if is_training:\n",
        "            dataset = dataset.repeat()\n",
        "        if one_batch:\n",
        "            dataset = dataset.take(params['batch_size'])\n",
        "            \n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(8)\n",
        "\n",
        "        return dataset\n",
        "    return input_fn\n",
        "\n",
        "\n",
        "def predict_input_fn(params):\n",
        "    batch_size = params['batch_size']\n",
        "    dataset = tf.data.TFRecordDataset(data_test_file).map(parser).cache().shuffle(batch_size)\n",
        "    style_images, content_images, _ = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
        "    \n",
        "    features = {'style_images': style_images, 'content_images': content_images}\n",
        "    return features, None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6i0DewZB02v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################### DATA SAVEING ###################################\n",
        " \n",
        "def images_to_zero_one(images):\n",
        "        return np.clip(np.array(images) * 0.5 + 0.5, 0., 1.)\n",
        "\n",
        "\n",
        "def save_imgs(epoch, images):\n",
        "    if not os.path.exists(GOOGLE_DRIVE_DIR):\n",
        "        os.mkdir(GOOGLE_DRIVE_DIR)\n",
        "\n",
        "    # Rescale images to 0 - 1\n",
        "    images = images_to_zero_one(images)\n",
        "    fig, axs = plt.subplots(R, C, figsize=(20,20))\n",
        "\n",
        "    for i in range(R):\n",
        "        for j in range(C):\n",
        "            axs[i,j].imshow(images[C*i + j])\n",
        "            axs[i,j].axis('off')\n",
        "\n",
        "    fig.savefig(os.path.join(GOOGLE_DRIVE_DIR, '{}.png'.format(epoch)))\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khVvoOzKB024",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################## MODEL #######################################\n",
        "\n",
        "def _relu(x):\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def _leaky_relu(x):\n",
        "    return tf.nn.leaky_relu(x, alpha=ALPHA)\n",
        "\n",
        "\n",
        "def _instance_norm(x):\n",
        "    return tf.contrib.layers.instance_norm(x)\n",
        "\n",
        "\n",
        "def _make_adain_norm(beta, gamma, index):\n",
        "    def _adain_norm(x):\n",
        "        mean, var = tf.nn.moments(x, [1, 2], keep_dims=True)\n",
        "        outputs = tf.nn.batch_normalization(x, mean, var, beta, gamma, variance_epsilon=1e-5, name='in_bn_{}'.format(index))\n",
        "        return outputs\n",
        "    return _adain_norm\n",
        "\n",
        "\n",
        "def _dense(x, neurons, name, activation=None):\n",
        "    return tf.layers.dense(x, neurons, name=name, activation=activation,\n",
        "                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "def _conv2d(x, filters, kernel_size, stride, name, activation=None):\n",
        "    return tf.layers.conv2d(x, filters, [kernel_size, kernel_size], \n",
        "                            strides=[stride, stride], activation=activation,\n",
        "                            padding='same', name=name,\n",
        "                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "def _pooling(x, kernel, stride, index):\n",
        "    return tf.layers.average_pooling2d(x, pool_size=kernel, strides=stride, name='pool_{}'.format(index))\n",
        "\n",
        "def _deconv2d(x, filters, stride, name, activation=None):\n",
        "    return tf.layers.conv2d_transpose(x, filters, [KERNEL_SIZE, KERNEL_SIZE],\n",
        "                                      strides=[stride, stride], activation=activation,\n",
        "                                      padding='same', name=name,\n",
        "                                      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "\n",
        "def convolution_block(x, filters, kernel_size, resize_factor, index, activation=_relu, activation_first=False, normalization=None):\n",
        "    if activation and activation_first:\n",
        "        x = activation(x)\n",
        "    x = _conv2d(x, kernel_size=kernel_size, filters=filters, stride=resize_factor, activation=None, name='conv_{}'.format(index))\n",
        "    if normalization:\n",
        "        x = normalization(x)\n",
        "    if activation and not activation_first:\n",
        "        x = activation(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def deconvolution_block(x, filters, resize_factor, index, activation=_relu, normalization=None):\n",
        "    x = _deconv2d(x, filters=filters, stride=resize_factor, activation=None, name='deconv_{}'.format(index))\n",
        "    if normalization:\n",
        "        x = normalization(x)\n",
        "    if activation:\n",
        "        x = activation(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def fully_connected_block(x, neurons, index, activation=_relu, normalization=None):\n",
        "    x = _dense(x, neurons=neurons, activation=None, name='fc_{}'.format(index))\n",
        "    if normalization:\n",
        "        x = normalization(x)\n",
        "    if activation:\n",
        "        x = activation(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def residual_block(x, filters_in, filters_out, index, kernel_size=3, activation=_relu, activation_first=False, normalization=None):\n",
        "    forwarded_x = convolution_block(x, filters_in, kernel_size, resize_factor=1, \n",
        "                                    index='res_con1_{}'.format(index), normalization=normalization,\n",
        "                                    activation_first=activation_first, activation=activation)\n",
        "    \n",
        "    forwarded_x = convolution_block(forwarded_x, filters_out, kernel_size, resize_factor=1, \n",
        "                                    index='res_con2_{}'.format(index), normalization=normalization,\n",
        "                                    activation_first=activation_first, activation=None)\n",
        "    \n",
        "    if filters_in != filters_out:\n",
        "        x = convolution_block(x, filters_out, kernel_size=1, resize_factor=1, index='res_con3_{}'.format(index), activation=None)\n",
        "    x = tf.add(forwarded_x, x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def adain_residual_block(x, beta, gamma, filters_in, filters_out, index, activation=_relu, activation_first=False):\n",
        "    with tf.variable_scope('adain_{}'.format(index)):\n",
        "        normalization = _make_adain_norm(beta, gamma, index)\n",
        "        return residual_block(x, filters_in, filters_out, index, 3, activation, activation_first, normalization)\n",
        "\n",
        "\n",
        "def content_encoder(x):\n",
        "    x = convolution_block(x, 64, kernel_size=7, resize_factor=2, normalization=_instance_norm, index='con1')\n",
        "    x = convolution_block(x, 128, kernel_size=KERNEL_SIZE, resize_factor=2, normalization=_instance_norm, index='con2')\n",
        "    x = convolution_block(x, 256, kernel_size=KERNEL_SIZE, resize_factor=2, normalization=_instance_norm, index='con3')\n",
        "    x = convolution_block(x, 512, kernel_size=KERNEL_SIZE, resize_factor=2, normalization=_instance_norm, index='con4')\n",
        "    \n",
        "    x = residual_block(x, 512, 512, index='res1', normalization=_instance_norm)\n",
        "    x = residual_block(x, 512, 512, index='res2', normalization=_instance_norm)\n",
        "    return x\n",
        "\n",
        "\n",
        "def class_encoder(x):\n",
        "    x = convolution_block(x, 64, kernel_size=7, resize_factor=1, index='cls1')\n",
        "    x = convolution_block(x, 128, kernel_size=KERNEL_SIZE, resize_factor=2, index='cls2')\n",
        "    x = convolution_block(x, 256, kernel_size=KERNEL_SIZE, resize_factor=2, index='cls3')\n",
        "    x = convolution_block(x, 512, kernel_size=KERNEL_SIZE, resize_factor=2, index='cls4')\n",
        "    x = convolution_block(x, 1024, kernel_size=KERNEL_SIZE, resize_factor=2, index='cls5')\n",
        "    x = _pooling(x, 3, 3, index='cls6')\n",
        "    return x\n",
        "\n",
        "\n",
        "def mlp(x, feature_number):\n",
        "    x = fully_connected_block(x, 256, 'mlp1')\n",
        "    x = fully_connected_block(x, 256, 'mlp2')\n",
        "    x = fully_connected_block(x, feature_number, 'mlp3', activation=None)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "def split_into_four_variable_sets(class_vars, num_features):\n",
        "    b1 = class_vars[:, :, :, :num_features]\n",
        "    g1 = class_vars[:, :, :, num_features:2*num_features]\n",
        "    b2 = class_vars[:, :, :, 2*num_features:3*num_features]\n",
        "    g2 = class_vars[:, :, :, 3*num_features:]\n",
        "    return b1, g1, b2, g2\n",
        "    \n",
        "\n",
        "def decoder(content_latent, class_latent):\n",
        "    # class code\n",
        "    encoder_features_num = content_latent.shape[3]\n",
        "    class_vars = mlp(class_latent, 4*encoder_features_num)\n",
        "    b1, g1, b2, g2 = split_into_four_variable_sets(class_vars, encoder_features_num)\n",
        "   \n",
        "    # ADAIN\n",
        "    x = adain_residual_block(content_latent, b1, g1, 512, 512, index='res3')\n",
        "    x = adain_residual_block(x, b2, g2, 512, 512, index='res4')\n",
        "\n",
        "    # Scale up\n",
        "    x = deconvolution_block(x, 512, resize_factor=2, normalization=_instance_norm, index='dec0')\n",
        "    x = deconvolution_block(x, 256, resize_factor=2, normalization=_instance_norm, index='dec1')\n",
        "    x = deconvolution_block(x, 128, resize_factor=2, normalization=_instance_norm, index='dec2')\n",
        "    x = deconvolution_block(x, CHANNELS, resize_factor=2, normalization=None, index='dec4', activation=tf.tanh)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "class Funit:\n",
        "\n",
        "    @staticmethod\n",
        "    def discriminator(x, label, scope='Discriminator'):\n",
        "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "            x = convolution_block(x, 64, kernel_size=7, resize_factor=1, index='disc_11')\n",
        "            \n",
        "            x = residual_block(x, 64, 64, 'disc_12', kernel_size=3, activation=_leaky_relu, activation_first=True)\n",
        "            x = residual_block(x, 64, 128, 'disc_13', kernel_size=3, activation=_leaky_relu, activation_first=True)\n",
        "            x = _pooling(x, 3, 2, 'disc_14')\n",
        "            \n",
        "            x = residual_block(x, 128, 128, 'disc_15', kernel_size=3, activation=_leaky_relu, activation_first=True)\n",
        "            x = residual_block(x, 128, 256, 'disc_16', kernel_size=3, activation=_leaky_relu, activation_first=True)\n",
        "            x = _pooling(x, 3, 2, 'disc_17')\n",
        "            \n",
        "            x = residual_block(x, 256, 256, 'disc_18', kernel_size=3, activation=_leaky_relu, activation_first=True)\n",
        "            x = residual_block(x, 256, 512, 'disc_19', kernel_size=3, activation=_leaky_relu, activation_first=True)\n",
        "            x = _pooling(x, 3, 2, 'disc_20')\n",
        "            \n",
        "            x = residual_block(x, 512, 512, 'disc_21', kernel_size=3, activation=_leaky_relu, activation_first=True)\n",
        "            x = residual_block(x, 512, 1024, 'disc_22', kernel_size=3, activation=_leaky_relu, activation_first=True)\n",
        "            x = _pooling(x, 3, 2, 'disc_23')\n",
        "            \n",
        "            x = residual_block(x, 1024, 1024, 'disc_24', kernel_size=3, activation=_leaky_relu, activation_first=True)\n",
        "            x = residual_block(x, 1024, 1024, 'disc_25', kernel_size=3, activation=_leaky_relu, activation_first=True)\n",
        "            \n",
        "            output = tf.layers.flatten(x)\n",
        "            output = _dense(output, NUM_CLASSES, 'disc_out')\n",
        "            output = tf.gather_nd(output, tf.expand_dims(label, axis=1), batch_dims=1)\n",
        "            \n",
        "            return output, x\n",
        "          \n",
        "    @staticmethod\n",
        "    def generator(image_content, image_style, scope='Generator'):\n",
        "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "            content_latent = content_encoder(image_content)\n",
        "            class_latent = class_encoder(image_style)\n",
        "            x = decoder(content_latent, class_latent)\n",
        "            return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSBN3P9whXDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# It's not exactly the norm, but taking mean instead of sum makes the losses more comparable\n",
        "def l1_norm(x):\n",
        "    return tf.reduce_mean(tf.math.abs(x), axis=[1,2,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcr7UF8SB029",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################ MODEL FUN #####################################\n",
        "def make_model_fn(model):\n",
        "\n",
        "    def model_fn(features, labels, mode, params):\n",
        "        with tf.variable_scope('inputs'):\n",
        "            content_images = features['content_images']\n",
        "            style_images = features['style_images']\n",
        "        generated_images = model.generator(content_images, style_images)\n",
        "        \n",
        "        # PREDICT #\n",
        "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "            predictions = {\n",
        "                'generated_images': generated_images,\n",
        "                'content_images': content_images,\n",
        "                'style_images': style_images\n",
        "            }\n",
        "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, predictions=predictions)\n",
        "        \n",
        "        # Labels\n",
        "        d_on_data_labels = tf.ones_like(labels)\n",
        "        d_on_g_labels = tf.zeros_like(labels)\n",
        "        \n",
        "        # Discriminator loss\n",
        "        d_on_data_results, d_on_data_features = model.discriminator(style_images, labels)\n",
        "        d_on_data_logits = tf.squeeze(d_on_data_results)\n",
        "       \n",
        "        d_on_g_results, d_on_g_features = model.discriminator(generated_images, labels)\n",
        "        d_on_g_logits = tf.squeeze(d_on_g_results)\n",
        "        \n",
        "        # Content reconstruction\n",
        "        generated_images_content_reconstruction = model.generator(content_images, content_images)\n",
        "        \n",
        "        with tf.variable_scope('losses'):\n",
        "            d_loss = tf.contrib.gan.losses.wargs.modified_discriminator_loss(\n",
        "                discriminator_real_outputs=d_on_data_logits,\n",
        "                discriminator_gen_outputs=d_on_g_logits,\n",
        "                reduction=tf.losses.Reduction.NONE,\n",
        "            )\n",
        "            d_loss_reduced = tf.reduce_mean(d_loss)\n",
        "\n",
        "            # Generator loss\n",
        "            g_loss_gan = tf.contrib.gan.losses.wargs.modified_generator_loss(\n",
        "                discriminator_gen_outputs=d_on_g_logits,\n",
        "                reduction=tf.losses.Reduction.NONE\n",
        "            )\n",
        "            g_loss_rec = LR_REC * l1_norm(generated_images_content_reconstruction - content_images)\n",
        "            g_loss_feat = LR_FEAT * l1_norm(d_on_g_features - d_on_data_features)\n",
        "            \n",
        "            g_loss_reduced = tf.reduce_mean(g_loss_feat)\n",
        "            \n",
        "        # TRAIN #\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            \n",
        "            with tf.variable_scope('optimizer'):\n",
        "                d_optimizer = tf.train.AdamOptimizer(learning_rate=D_LR, beta1=0.5)\n",
        "                d_optimizer = tf.contrib.tpu.CrossShardOptimizer(d_optimizer)\n",
        "            \n",
        "                g_optimizer = tf.train.AdamOptimizer(learning_rate=G_LR, beta1=0.5)\n",
        "                g_optimizer = tf.contrib.tpu.CrossShardOptimizer(g_optimizer)\n",
        "         \n",
        "                with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "                    d_step = d_optimizer.minimize(d_loss_reduced, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                                                                     scope='Discriminator'))\n",
        "                    g_step = g_optimizer.minimize(g_loss_reduced, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                                                                     scope='Generator'))\n",
        "                    increment_step = tf.assign_add(tf.train.get_or_create_global_step(), 1)\n",
        "                    joint_op = tf.group([d_step, g_step, increment_step])\n",
        "\n",
        "                    a = tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=d_loss_reduced+g_loss_reduced, train_op=joint_op)\n",
        "                    return a\n",
        "\n",
        "        # EVAL #\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "            def _eval_metric_fn(d_loss, g_loss_1, g_loss_2, g_loss_3, d_real_labels, d_gen_lanels, d_real_logits, d_gen_logits):\n",
        "                return {\n",
        "                    'discriminator_loss': tf.metrics.mean(d_loss),\n",
        "                    'generator_loss': tf.metrics.mean(g_loss_1),\n",
        "                    'generator_loss_recon': tf.metrics.mean(g_loss_2),\n",
        "                    'generator_loss_match': tf.metrics.mean(g_loss_3),\n",
        "                    'discriminator_real_accuracy': tf.metrics.accuracy(labels=d_real_labels, predictions=tf.math.round(tf.sigmoid(d_real_logits))),\n",
        "                    'discriminator_gen_accuracy': tf.metrics.accuracy(labels=d_gen_lanels, predictions=tf.math.round(tf.sigmoid(d_gen_logits))),\n",
        "                }\n",
        "\n",
        "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=d_loss_reduced + g_loss_reduced,\n",
        "                                                   eval_metrics=(_eval_metric_fn, [d_loss, g_loss_gan, g_loss_rec, g_loss_feat,\n",
        "                                                                                   d_on_data_labels, d_on_g_labels,\n",
        "                                                                                   d_on_data_logits, d_on_g_logits]))\n",
        "    return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5rb586jB03F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################ ESTIMATORS ####################################\n",
        "\n",
        "def make_estimators(model, only_cpu=False):\n",
        "    model_fn = make_model_fn(model)\n",
        "    \n",
        "    config = tf.contrib.tpu.RunConfig(\n",
        "        master=TF_MASTER,\n",
        "        save_checkpoints_steps=EVAL_EPOCHS,\n",
        "        save_checkpoints_secs=None,\n",
        "        save_summary_steps=EVAL_EPOCHS,\n",
        "        model_dir=MODEL_DIR,\n",
        "        keep_checkpoint_max=3,\n",
        "        tpu_config=tf.contrib.tpu.TPUConfig(iterations_per_loop=EVAL_EPOCHS))\n",
        "\n",
        "    if not only_cpu:\n",
        "        # TPU-based estimator used for TRAIN and EVAL\n",
        "        est = tf.contrib.tpu.TPUEstimator(\n",
        "            model_fn=model_fn,\n",
        "            use_tpu=True,\n",
        "            config=config,\n",
        "            train_batch_size=BATCH_SIZE,\n",
        "            eval_batch_size=BATCH_SIZE)\n",
        "    else:\n",
        "        est = None\n",
        "\n",
        "    # CPU-based estimator used for PREDICT (generating images)\n",
        "    cpu_est = tf.contrib.tpu.TPUEstimator(\n",
        "        model_fn=model_fn,\n",
        "        use_tpu=False,\n",
        "        config=config,\n",
        "        predict_batch_size=EXAMPLES)\n",
        "    \n",
        "    return est, cpu_est"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nIuQqdWB03O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################# TRAINING #####################################\n",
        "\n",
        "def train(est, cpu_est):\n",
        "    current_step = estimator._load_global_step_from_checkpoint_dir(MODEL_DIR)\n",
        "    print('Starting training')\n",
        "\n",
        "    while current_step < EPOCHS:\n",
        "        next_checkpoint = int(min(current_step + EVAL_EPOCHS, EPOCHS))\n",
        "        est.train(input_fn=make_input_fn(), max_steps=next_checkpoint)\n",
        "        current_step = next_checkpoint\n",
        "        print('Finished training step %d' % current_step)\n",
        "\n",
        "        # Evaluation\n",
        "        metrics = est.evaluate(input_fn=make_input_fn(False), steps=1)\n",
        "        print('Finished evaluating')\n",
        "        print(metrics)\n",
        "\n",
        "        # Render some generated images\n",
        "        generated_iter = cpu_est.predict(input_fn=make_input_fn(False, one_batch=True))\n",
        "        images = [np.concatenate([p['content_images'], p['style_images'], p['generated_images']], axis=1) for p in generated_iter]\n",
        "        save_imgs(str(current_step), images)\n",
        "        print('Finished generating images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STjYktznB03T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_experiment():\n",
        "    setup()\n",
        "    upload_credentials()\n",
        "    model = Funit()\n",
        "    est, cpu_est = make_estimators(model)\n",
        "    train(est, cpu_est)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eImay3kpN2C",
        "colab_type": "code",
        "outputId": "4414ef0d-efd7-42fc-9f7b-8b15c9a80bfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "try:\n",
        "    do_experiment()\n",
        "except Exception as e:\n",
        "    print (e)\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0905 09:18:13.479905 140244153718656 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0905 09:18:14.539459 140244153718656 estimator.py:1984] Estimator's model_fn (<function make_model_fn.<locals>.model_fn at 0x7f8cdb4e2ae8>) includes params argument, but params are not passed to Estimator.\n",
            "I0905 09:18:14.542223 140244153718656 estimator.py:209] Using config: {'_model_dir': 'gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/', '_tf_random_seed': None, '_save_summary_steps': 1000, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8ce9b1a8d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.16.197.58:8470', '_evaluation_master': 'grpc://10.16.197.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "I0905 09:18:14.546774 140244153718656 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "W0905 09:18:14.551433 140244153718656 estimator.py:1984] Estimator's model_fn (<function make_model_fn.<locals>.model_fn at 0x7f8cdb4e2ae8>) includes params argument, but params are not passed to Estimator.\n",
            "I0905 09:18:14.553510 140244153718656 estimator.py:209] Using config: {'_model_dir': 'gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/', '_tf_random_seed': None, '_save_summary_steps': 1000, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8ce9a7c7b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.16.197.58:8470', '_evaluation_master': 'grpc://10.16.197.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "I0905 09:18:14.556622 140244153718656 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "W0905 09:18:14.559396 140244153718656 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n",
            "I0905 09:18:15.784952 140244153718656 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.16.197.58:8470) for TPU system metadata.\n",
            "I0905 09:18:15.793798 140244153718656 tpu_system_metadata.py:148] Found TPU system:\n",
            "I0905 09:18:15.797049 140244153718656 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "I0905 09:18:15.799024 140244153718656 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "I0905 09:18:15.799770 140244153718656 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "I0905 09:18:15.801796 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 10103736519151559135)\n",
            "I0905 09:18:15.804376 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14307464423895776771)\n",
            "I0905 09:18:15.806001 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16736140360515388554)\n",
            "I0905 09:18:15.809059 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1080445485603175114)\n",
            "I0905 09:18:15.810828 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8772829896936041461)\n",
            "I0905 09:18:15.813150 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10544820647022029792)\n",
            "I0905 09:18:15.814071 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 897935333828189466)\n",
            "I0905 09:18:15.815884 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3065538040404827238)\n",
            "I0905 09:18:15.818147 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17331022150534508890)\n",
            "I0905 09:18:15.819894 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 14645692322353819239)\n",
            "I0905 09:18:15.820539 140244153718656 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14186478871560158138)\n",
            "W0905 09:18:15.835324 140244153718656 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "I0905 09:18:15.857376 140244153718656 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0905 09:18:15.969033 140244153718656 deprecation.py:323] From <ipython-input-6-ffd348ae6cfc>:31: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "W0905 09:18:16.748025 140244153718656 deprecation.py:323] From <ipython-input-6-ffd348ae6cfc>:34: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.AveragePooling2D instead.\n",
            "W0905 09:18:16.860508 140244153718656 deprecation.py:323] From <ipython-input-6-ffd348ae6cfc>:24: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0905 09:18:17.492715 140244153718656 deprecation.py:323] From <ipython-input-6-ffd348ae6cfc>:40: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "W0905 09:18:18.702721 140244153718656 deprecation.py:323] From <ipython-input-6-ffd348ae6cfc>:175: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0905 09:18:19.931850 140244153718656 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "I0905 09:18:26.496491 140244153718656 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0905 09:18:26.706587 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:18:29.039001 140244153718656 tpu_estimator.py:499] TPU job name tpu_worker\n",
            "I0905 09:18:30.059722 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:18:34.813891 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:18:35.394124 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:18:40.614377 140244153718656 basic_session_run_hooks.py:606] Saving checkpoints for 0 into gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt.\n",
            "W0905 09:19:03.541502 140244153718656 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "I0905 09:19:04.725979 140244153718656 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0905 09:19:04.730004 140244153718656 session_support.py:332] Installing graceful shutdown hook.\n",
            "I0905 09:19:04.735459 140244153718656 session_support.py:82] Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "I0905 09:19:04.741213 140244153718656 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0905 09:19:04.747260 140244153718656 tpu_estimator.py:557] Init TPU system\n",
            "I0905 09:19:10.021661 140244153718656 tpu_estimator.py:566] Initialized TPU in 5 seconds\n",
            "I0905 09:19:10.023251 140242790700800 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0905 09:19:10.024707 140242782308096 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0905 09:19:10.605755 140244153718656 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0905 09:19:10.607617 140244153718656 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0905 09:19:36.576826 140242782308096 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0905 09:20:36.763640 140242782308096 tpu_estimator.py:275] Outfeed finished for iteration (0, 231)\n",
            "I0905 09:21:36.952018 140242782308096 tpu_estimator.py:275] Outfeed finished for iteration (0, 462)\n",
            "I0905 09:22:37.138710 140242782308096 tpu_estimator.py:275] Outfeed finished for iteration (0, 693)\n",
            "I0905 09:23:37.327091 140242782308096 tpu_estimator.py:275] Outfeed finished for iteration (0, 924)\n",
            "I0905 09:23:57.615765 140244153718656 basic_session_run_hooks.py:606] Saving checkpoints for 1000 into gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt.\n",
            "I0905 09:24:18.931851 140244153718656 basic_session_run_hooks.py:262] loss = 1.3050706, step = 1000\n",
            "I0905 09:24:19.421938 140244153718656 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0905 09:24:19.423121 140244153718656 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0905 09:24:19.427756 140242790700800 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0905 09:24:19.428629 140242790700800 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0905 09:24:19.430242 140244153718656 error_handling.py:96] infeed marked as finished\n",
            "I0905 09:24:19.431265 140244153718656 tpu_estimator.py:602] Stop output thread controller\n",
            "I0905 09:24:19.432199 140244153718656 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0905 09:24:19.433370 140242782308096 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0905 09:24:19.434508 140242782308096 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0905 09:24:19.435801 140244153718656 error_handling.py:96] outfeed marked as finished\n",
            "I0905 09:24:19.436758 140244153718656 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0905 09:24:21.387973 140244153718656 estimator.py:368] Loss for final step: 1.3050706.\n",
            "I0905 09:24:21.389823 140244153718656 error_handling.py:96] training_loop marked as finished\n",
            "I0905 09:24:21.546342 140244153718656 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished training step 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0905 09:24:24.526867 140244153718656 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3154: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "I0905 09:24:25.837649 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:24:25.861713 140244153718656 evaluation.py:255] Starting evaluation at 2019-09-05T09:24:25Z\n",
            "I0905 09:24:25.862765 140244153718656 tpu_estimator.py:499] TPU job name tpu_worker\n",
            "I0905 09:24:26.172353 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "W0905 09:24:26.173954 140244153718656 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0905 09:24:26.242726 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-1000\n",
            "I0905 09:24:31.088489 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:24:31.268214 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:24:31.656107 140244153718656 tpu_estimator.py:557] Init TPU system\n",
            "I0905 09:24:39.732456 140244153718656 tpu_estimator.py:566] Initialized TPU in 8 seconds\n",
            "I0905 09:24:39.735401 140242773657344 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0905 09:24:39.737645 140242765264640 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0905 09:24:39.924473 140244153718656 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0905 09:24:40.081931 140244153718656 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0905 09:24:40.083087 140244153718656 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0905 09:24:50.872300 140244153718656 evaluation.py:167] Evaluation [1/1]\n",
            "I0905 09:24:50.873782 140244153718656 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0905 09:24:50.874708 140244153718656 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0905 09:24:50.872807 140242765264640 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0905 09:24:50.876313 140242773657344 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0905 09:24:50.878822 140242773657344 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0905 09:24:50.880534 140244153718656 error_handling.py:96] infeed marked as finished\n",
            "I0905 09:24:50.882164 140244153718656 tpu_estimator.py:602] Stop output thread controller\n",
            "I0905 09:24:50.883596 140244153718656 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0905 09:24:50.884588 140242765264640 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0905 09:24:50.885532 140242765264640 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0905 09:24:50.889821 140244153718656 error_handling.py:96] outfeed marked as finished\n",
            "I0905 09:24:50.890953 140244153718656 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0905 09:24:51.669055 140244153718656 evaluation.py:275] Finished evaluation at 2019-09-05-09:24:51\n",
            "I0905 09:24:51.670066 140244153718656 estimator.py:2039] Saving dict for global step 1000: discriminator_gen_accuracy = 0.8955078, discriminator_loss = 1.1916072, discriminator_real_accuracy = 0.36914062, generator_loss = 1.3646863, generator_loss_match = 0.05693698, generator_loss_recon = 0.035871666, global_step = 1000, loss = 1.2522522\n",
            "I0905 09:24:53.794989 140244153718656 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1000: gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-1000\n",
            "I0905 09:24:54.392602 140244153718656 error_handling.py:96] evaluation_loop marked as finished\n",
            "I0905 09:24:54.528095 140244153718656 estimator.py:1145] Calling model_fn.\n",
            "I0905 09:24:54.529381 140244153718656 tpu_estimator.py:2965] Running infer on CPU\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished evaluating\n",
            "{'discriminator_gen_accuracy': 0.8955078, 'discriminator_loss': 1.1916072, 'discriminator_real_accuracy': 0.36914062, 'generator_loss': 1.3646863, 'generator_loss_match': 0.05693698, 'generator_loss_recon': 0.035871666, 'loss': 1.2522522, 'global_step': 1000}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:24:55.473798 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:24:55.679610 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:24:55.725257 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-1000\n",
            "I0905 09:24:56.145298 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:24:56.174211 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:24:56.668476 140244153718656 error_handling.py:96] prediction_loop marked as finished\n",
            "I0905 09:24:56.671944 140244153718656 error_handling.py:96] prediction_loop marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished generating images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:24:58.046627 140244153718656 estimator.py:1145] Calling model_fn.\n",
            "I0905 09:25:07.543331 140244153718656 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0905 09:25:07.756565 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:25:07.758117 140244153718656 tpu_estimator.py:499] TPU job name tpu_worker\n",
            "I0905 09:25:08.807574 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:25:08.964574 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-1000\n",
            "W0905 09:25:18.182051 140244153718656 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "I0905 09:25:19.111016 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:25:19.702914 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:25:25.261392 140244153718656 basic_session_run_hooks.py:606] Saving checkpoints for 1000 into gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt.\n",
            "I0905 09:25:50.275974 140244153718656 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0905 09:25:50.277376 140244153718656 session_support.py:332] Installing graceful shutdown hook.\n",
            "I0905 09:25:50.285929 140244153718656 session_support.py:82] Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "I0905 09:25:50.290816 140244153718656 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0905 09:25:50.299136 140244153718656 tpu_estimator.py:557] Init TPU system\n",
            "I0905 09:26:00.620231 140244153718656 tpu_estimator.py:566] Initialized TPU in 10 seconds\n",
            "I0905 09:26:00.622061 140242765264640 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0905 09:26:00.623947 140242756871936 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0905 09:26:01.258920 140244153718656 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0905 09:26:01.260053 140244153718656 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0905 09:26:29.031774 140242756871936 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0905 09:27:29.219594 140242756871936 tpu_estimator.py:275] Outfeed finished for iteration (0, 231)\n",
            "I0905 09:28:29.406194 140242756871936 tpu_estimator.py:275] Outfeed finished for iteration (0, 462)\n",
            "I0905 09:29:29.593406 140242756871936 tpu_estimator.py:275] Outfeed finished for iteration (0, 693)\n",
            "I0905 09:30:29.781179 140242756871936 tpu_estimator.py:275] Outfeed finished for iteration (0, 924)\n",
            "I0905 09:30:50.088935 140244153718656 basic_session_run_hooks.py:606] Saving checkpoints for 2000 into gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt.\n",
            "I0905 09:31:23.448129 140244153718656 basic_session_run_hooks.py:262] loss = 0.84159315, step = 2000\n",
            "I0905 09:31:24.123456 140244153718656 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0905 09:31:24.127619 140244153718656 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0905 09:31:24.129236 140242765264640 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0905 09:31:24.130303 140242765264640 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0905 09:31:24.131502 140244153718656 error_handling.py:96] infeed marked as finished\n",
            "I0905 09:31:24.132344 140244153718656 tpu_estimator.py:602] Stop output thread controller\n",
            "I0905 09:31:24.133204 140244153718656 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0905 09:31:24.134633 140242756871936 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0905 09:31:24.135558 140242756871936 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0905 09:31:24.142243 140244153718656 error_handling.py:96] outfeed marked as finished\n",
            "I0905 09:31:24.143663 140244153718656 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0905 09:31:26.257383 140244153718656 estimator.py:368] Loss for final step: 0.84159315.\n",
            "I0905 09:31:26.258710 140244153718656 error_handling.py:96] training_loop marked as finished\n",
            "I0905 09:31:26.447575 140244153718656 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished training step 2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:31:31.304528 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:31:31.334520 140244153718656 evaluation.py:255] Starting evaluation at 2019-09-05T09:31:31Z\n",
            "I0905 09:31:31.335986 140244153718656 tpu_estimator.py:499] TPU job name tpu_worker\n",
            "I0905 09:31:31.660024 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:31:31.714771 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-2000\n",
            "I0905 09:31:37.339213 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:31:37.509065 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:31:37.876461 140244153718656 tpu_estimator.py:557] Init TPU system\n",
            "I0905 09:31:45.816019 140244153718656 tpu_estimator.py:566] Initialized TPU in 7 seconds\n",
            "I0905 09:31:45.820555 140242765264640 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0905 09:31:45.822364 140242756871936 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0905 09:31:46.013583 140244153718656 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0905 09:31:46.175002 140244153718656 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0905 09:31:46.176403 140244153718656 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0905 09:31:57.372791 140242756871936 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0905 09:31:57.383444 140244153718656 evaluation.py:167] Evaluation [1/1]\n",
            "I0905 09:31:57.386796 140244153718656 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0905 09:31:57.387734 140244153718656 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0905 09:31:57.388657 140242765264640 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0905 09:31:57.389404 140242765264640 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0905 09:31:57.390496 140244153718656 error_handling.py:96] infeed marked as finished\n",
            "I0905 09:31:57.391545 140244153718656 tpu_estimator.py:602] Stop output thread controller\n",
            "I0905 09:31:57.393000 140244153718656 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0905 09:31:57.396574 140242756871936 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0905 09:31:57.397602 140242756871936 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0905 09:31:57.398616 140244153718656 error_handling.py:96] outfeed marked as finished\n",
            "I0905 09:31:57.400571 140244153718656 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0905 09:31:58.158081 140244153718656 evaluation.py:275] Finished evaluation at 2019-09-05-09:31:58\n",
            "I0905 09:31:58.159366 140244153718656 estimator.py:2039] Saving dict for global step 2000: discriminator_gen_accuracy = 1.0, discriminator_loss = 0.6207279, discriminator_real_accuracy = 0.87402344, generator_loss = 2.557304, generator_loss_match = 0.22748345, generator_loss_recon = 0.036412545, global_step = 2000, loss = 0.8176326\n",
            "I0905 09:31:58.541349 140244153718656 estimator.py:2099] Saving 'checkpoint_path' summary for global step 2000: gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-2000\n",
            "I0905 09:31:58.968517 140244153718656 error_handling.py:96] evaluation_loop marked as finished\n",
            "I0905 09:31:59.120179 140244153718656 estimator.py:1145] Calling model_fn.\n",
            "I0905 09:31:59.122137 140244153718656 tpu_estimator.py:2965] Running infer on CPU\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished evaluating\n",
            "{'discriminator_gen_accuracy': 1.0, 'discriminator_loss': 0.6207279, 'discriminator_real_accuracy': 0.87402344, 'generator_loss': 2.557304, 'generator_loss_match': 0.22748345, 'generator_loss_recon': 0.036412545, 'loss': 0.8176326, 'global_step': 2000}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:31:59.861027 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:32:00.424056 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:32:00.466635 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-2000\n",
            "I0905 09:32:00.883054 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:32:00.904283 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:32:01.321534 140244153718656 error_handling.py:96] prediction_loop marked as finished\n",
            "I0905 09:32:01.322865 140244153718656 error_handling.py:96] prediction_loop marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished generating images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:32:02.633596 140244153718656 estimator.py:1145] Calling model_fn.\n",
            "I0905 09:32:12.715480 140244153718656 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0905 09:32:12.939562 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:32:12.941018 140244153718656 tpu_estimator.py:499] TPU job name tpu_worker\n",
            "I0905 09:32:13.759832 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:32:13.922849 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-2000\n",
            "I0905 09:32:24.005464 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:32:24.583865 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:32:30.173880 140244153718656 basic_session_run_hooks.py:606] Saving checkpoints for 2000 into gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt.\n",
            "I0905 09:32:52.905242 140244153718656 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0905 09:32:52.906764 140244153718656 session_support.py:332] Installing graceful shutdown hook.\n",
            "I0905 09:32:52.911649 140244153718656 session_support.py:82] Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "I0905 09:32:52.921230 140244153718656 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0905 09:32:52.927983 140244153718656 tpu_estimator.py:557] Init TPU system\n",
            "I0905 09:33:03.486621 140244153718656 tpu_estimator.py:566] Initialized TPU in 10 seconds\n",
            "I0905 09:33:03.488227 140242756871936 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0905 09:33:03.489869 140242748479232 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0905 09:33:04.129848 140244153718656 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0905 09:33:04.131141 140244153718656 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0905 09:33:32.148910 140242748479232 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0905 09:34:32.336168 140242748479232 tpu_estimator.py:275] Outfeed finished for iteration (0, 231)\n",
            "I0905 09:35:32.522403 140242748479232 tpu_estimator.py:275] Outfeed finished for iteration (0, 462)\n",
            "I0905 09:36:32.709297 140242748479232 tpu_estimator.py:275] Outfeed finished for iteration (0, 693)\n",
            "I0905 09:37:32.896551 140242748479232 tpu_estimator.py:275] Outfeed finished for iteration (0, 924)\n",
            "I0905 09:37:53.197444 140244153718656 basic_session_run_hooks.py:606] Saving checkpoints for 3000 into gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt.\n",
            "W0905 09:38:12.568619 140244153718656 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "I0905 09:38:14.872040 140244153718656 basic_session_run_hooks.py:262] loss = 0.8264117, step = 3000\n",
            "I0905 09:38:15.362170 140244153718656 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0905 09:38:15.363367 140244153718656 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0905 09:38:15.370010 140242756871936 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0905 09:38:15.370815 140242756871936 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0905 09:38:15.377659 140244153718656 error_handling.py:96] infeed marked as finished\n",
            "I0905 09:38:15.379313 140244153718656 tpu_estimator.py:602] Stop output thread controller\n",
            "I0905 09:38:15.381734 140244153718656 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0905 09:38:15.383810 140242748479232 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0905 09:38:15.384769 140242748479232 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0905 09:38:15.386485 140244153718656 error_handling.py:96] outfeed marked as finished\n",
            "I0905 09:38:15.388113 140244153718656 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0905 09:38:17.528349 140244153718656 estimator.py:368] Loss for final step: 0.8264117.\n",
            "I0905 09:38:17.529547 140244153718656 error_handling.py:96] training_loop marked as finished\n",
            "I0905 09:38:17.692108 140244153718656 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished training step 3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:38:22.528094 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:38:22.754593 140244153718656 evaluation.py:255] Starting evaluation at 2019-09-05T09:38:22Z\n",
            "I0905 09:38:22.755659 140244153718656 tpu_estimator.py:499] TPU job name tpu_worker\n",
            "I0905 09:38:23.069351 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:38:23.121797 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-3000\n",
            "I0905 09:38:27.495250 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:38:27.664600 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:38:28.097707 140244153718656 tpu_estimator.py:557] Init TPU system\n",
            "I0905 09:38:35.760734 140244153718656 tpu_estimator.py:566] Initialized TPU in 7 seconds\n",
            "I0905 09:38:35.762440 140243170989824 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0905 09:38:35.766881 140243162597120 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0905 09:38:35.965338 140244153718656 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0905 09:38:36.146298 140244153718656 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0905 09:38:36.147615 140244153718656 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0905 09:38:47.554091 140243162597120 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0905 09:38:47.556741 140244153718656 evaluation.py:167] Evaluation [1/1]\n",
            "I0905 09:38:47.558482 140244153718656 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0905 09:38:47.559553 140244153718656 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0905 09:38:47.560725 140243170989824 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0905 09:38:47.564140 140243170989824 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0905 09:38:47.567915 140244153718656 error_handling.py:96] infeed marked as finished\n",
            "I0905 09:38:47.569129 140244153718656 tpu_estimator.py:602] Stop output thread controller\n",
            "I0905 09:38:47.575094 140244153718656 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0905 09:38:47.578027 140243162597120 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0905 09:38:47.579498 140243162597120 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0905 09:38:47.581083 140244153718656 error_handling.py:96] outfeed marked as finished\n",
            "I0905 09:38:47.582843 140244153718656 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0905 09:38:48.344202 140244153718656 evaluation.py:275] Finished evaluation at 2019-09-05-09:38:48\n",
            "I0905 09:38:48.345307 140244153718656 estimator.py:2039] Saving dict for global step 3000: discriminator_gen_accuracy = 1.0, discriminator_loss = 0.44024038, discriminator_real_accuracy = 0.9707031, generator_loss = 4.2064114, generator_loss_match = 0.28914332, generator_loss_recon = 0.034988195, global_step = 3000, loss = 0.732635\n",
            "I0905 09:38:48.688413 140244153718656 estimator.py:2099] Saving 'checkpoint_path' summary for global step 3000: gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-3000\n",
            "I0905 09:38:49.054245 140244153718656 error_handling.py:96] evaluation_loop marked as finished\n",
            "I0905 09:38:49.204309 140244153718656 estimator.py:1145] Calling model_fn.\n",
            "I0905 09:38:49.205487 140244153718656 tpu_estimator.py:2965] Running infer on CPU\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished evaluating\n",
            "{'discriminator_gen_accuracy': 1.0, 'discriminator_loss': 0.44024038, 'discriminator_real_accuracy': 0.9707031, 'generator_loss': 4.2064114, 'generator_loss_match': 0.28914332, 'generator_loss_recon': 0.034988195, 'loss': 0.732635, 'global_step': 3000}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:38:49.937898 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:38:50.151231 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:38:50.195724 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-3000\n",
            "I0905 09:38:50.595987 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:38:50.625941 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:38:51.029877 140244153718656 error_handling.py:96] prediction_loop marked as finished\n",
            "I0905 09:38:51.031407 140244153718656 error_handling.py:96] prediction_loop marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished generating images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:38:52.219601 140244153718656 estimator.py:1145] Calling model_fn.\n",
            "I0905 09:39:02.197644 140244153718656 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0905 09:39:02.416108 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:39:02.417608 140244153718656 tpu_estimator.py:499] TPU job name tpu_worker\n",
            "I0905 09:39:03.564617 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:39:03.720039 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-3000\n",
            "I0905 09:39:13.462405 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:39:14.048903 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:39:19.724794 140244153718656 basic_session_run_hooks.py:606] Saving checkpoints for 3000 into gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt.\n",
            "I0905 09:39:46.755552 140244153718656 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0905 09:39:46.757038 140244153718656 session_support.py:332] Installing graceful shutdown hook.\n",
            "I0905 09:39:46.769377 140244153718656 session_support.py:82] Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "I0905 09:39:46.772755 140244153718656 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0905 09:39:46.781818 140244153718656 tpu_estimator.py:557] Init TPU system\n",
            "I0905 09:39:57.341480 140244153718656 tpu_estimator.py:566] Initialized TPU in 10 seconds\n",
            "I0905 09:39:57.343169 140242756871936 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0905 09:39:57.344754 140242748479232 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0905 09:39:57.958352 140244153718656 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0905 09:39:57.959751 140244153718656 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0905 09:40:26.248777 140242748479232 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0905 09:41:26.430291 140242748479232 tpu_estimator.py:275] Outfeed finished for iteration (0, 231)\n",
            "I0905 09:42:26.614184 140242748479232 tpu_estimator.py:275] Outfeed finished for iteration (0, 462)\n",
            "I0905 09:43:26.797162 140242748479232 tpu_estimator.py:275] Outfeed finished for iteration (0, 693)\n",
            "I0905 09:44:26.980008 140242748479232 tpu_estimator.py:275] Outfeed finished for iteration (0, 924)\n",
            "I0905 09:44:47.284209 140244153718656 basic_session_run_hooks.py:606] Saving checkpoints for 4000 into gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt.\n",
            "I0905 09:45:09.983103 140244153718656 basic_session_run_hooks.py:262] loss = 55.41719, step = 4000\n",
            "I0905 09:45:10.675258 140244153718656 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0905 09:45:10.676678 140244153718656 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0905 09:45:10.682148 140242756871936 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0905 09:45:10.686126 140242756871936 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0905 09:45:10.693370 140244153718656 error_handling.py:96] infeed marked as finished\n",
            "I0905 09:45:10.696332 140244153718656 tpu_estimator.py:602] Stop output thread controller\n",
            "I0905 09:45:10.698042 140244153718656 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0905 09:45:10.701265 140242748479232 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0905 09:45:10.703734 140242748479232 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0905 09:45:10.705710 140244153718656 error_handling.py:96] outfeed marked as finished\n",
            "I0905 09:45:10.706856 140244153718656 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0905 09:45:12.867203 140244153718656 estimator.py:368] Loss for final step: 55.41719.\n",
            "I0905 09:45:12.869062 140244153718656 error_handling.py:96] training_loop marked as finished\n",
            "I0905 09:45:13.053363 140244153718656 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished training step 4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:45:18.049283 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:45:18.074050 140244153718656 evaluation.py:255] Starting evaluation at 2019-09-05T09:45:18Z\n",
            "I0905 09:45:18.075277 140244153718656 tpu_estimator.py:499] TPU job name tpu_worker\n",
            "I0905 09:45:18.406098 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:45:18.452857 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-4000\n",
            "I0905 09:45:23.055150 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:45:23.256756 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:45:23.649071 140244153718656 tpu_estimator.py:557] Init TPU system\n",
            "I0905 09:45:31.545512 140244153718656 tpu_estimator.py:566] Initialized TPU in 7 seconds\n",
            "I0905 09:45:31.550544 140242773657344 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0905 09:45:31.554878 140242756871936 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0905 09:45:31.739309 140244153718656 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0905 09:45:31.902148 140244153718656 tpu_estimator.py:590] Enqueue next (1) batch(es) of data to infeed.\n",
            "I0905 09:45:31.906611 140244153718656 tpu_estimator.py:594] Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0905 09:45:42.880004 140242756871936 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0905 09:45:42.882176 140244153718656 evaluation.py:167] Evaluation [1/1]\n",
            "I0905 09:45:42.883204 140244153718656 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0905 09:45:42.883882 140244153718656 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0905 09:45:42.884566 140242773657344 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0905 09:45:42.885785 140242773657344 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0905 09:45:42.886749 140244153718656 error_handling.py:96] infeed marked as finished\n",
            "I0905 09:45:42.888049 140244153718656 tpu_estimator.py:602] Stop output thread controller\n",
            "I0905 09:45:42.889258 140244153718656 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0905 09:45:42.890269 140242756871936 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0905 09:45:42.891236 140242756871936 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0905 09:45:42.892422 140244153718656 error_handling.py:96] outfeed marked as finished\n",
            "I0905 09:45:42.896093 140244153718656 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0905 09:45:43.667426 140244153718656 evaluation.py:275] Finished evaluation at 2019-09-05-09:45:43\n",
            "I0905 09:45:43.668901 140244153718656 estimator.py:2039] Saving dict for global step 4000: discriminator_gen_accuracy = 0.68847656, discriminator_loss = 41.347298, discriminator_real_accuracy = 0.4580078, generator_loss = 35.550095, generator_loss_match = 22.975864, generator_loss_recon = 0.060193684, global_step = 4000, loss = 59.550377\n",
            "I0905 09:45:44.112085 140244153718656 estimator.py:2099] Saving 'checkpoint_path' summary for global step 4000: gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-4000\n",
            "I0905 09:45:44.535197 140244153718656 error_handling.py:96] evaluation_loop marked as finished\n",
            "I0905 09:45:44.701623 140244153718656 estimator.py:1145] Calling model_fn.\n",
            "I0905 09:45:44.702938 140244153718656 tpu_estimator.py:2965] Running infer on CPU\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished evaluating\n",
            "{'discriminator_gen_accuracy': 0.68847656, 'discriminator_loss': 41.347298, 'discriminator_real_accuracy': 0.4580078, 'generator_loss': 35.550095, 'generator_loss_match': 22.975864, 'generator_loss_recon': 0.060193684, 'loss': 59.550377, 'global_step': 4000}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:45:45.800510 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:45:46.019326 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:45:46.067250 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-4000\n",
            "I0905 09:45:46.515543 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:45:46.534317 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:45:46.948976 140244153718656 error_handling.py:96] prediction_loop marked as finished\n",
            "I0905 09:45:46.950840 140244153718656 error_handling.py:96] prediction_loop marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished generating images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0905 09:45:47.970989 140244153718656 estimator.py:1145] Calling model_fn.\n",
            "I0905 09:45:58.355094 140244153718656 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0905 09:45:58.580703 140244153718656 estimator.py:1147] Done calling model_fn.\n",
            "I0905 09:45:58.582417 140244153718656 tpu_estimator.py:499] TPU job name tpu_worker\n",
            "I0905 09:45:59.442599 140244153718656 monitored_session.py:240] Graph was finalized.\n",
            "I0905 09:45:59.580916 140244153718656 saver.py:1280] Restoring parameters from gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt-4000\n",
            "I0905 09:46:09.144385 140244153718656 session_manager.py:500] Running local_init_op.\n",
            "I0905 09:46:09.720022 140244153718656 session_manager.py:502] Done running local_init_op.\n",
            "I0905 09:46:15.462837 140244153718656 basic_session_run_hooks.py:606] Saving checkpoints for 4000 into gs://tputestingmnist/FUNIT/FUNIT_only_gen_42/model.ckpt.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}