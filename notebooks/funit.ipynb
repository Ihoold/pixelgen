{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "pix2pix.ipynb",
   "version": "0.3.2",
   "provenance": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "accelerator": "TPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "y-KtZcaWB02O",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from unittest import mock\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.estimator import estimator\n",
    "from google.colab import drive, auth"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CCzCaKLPB02f",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#################################### SETUP #####################################\n",
    "\n",
    "def setup():\n",
    "    drive.mount('/content/gdrive')\n",
    "    auth.authenticate_user()\n",
    "\n",
    "\n",
    "def upload_credentials():\n",
    "    # Upload credentials to TPU.\n",
    "    with tf.Session(TF_MASTER) as sess:    \n",
    "        with open('/content/adc.json', 'r') as f:\n",
    "            auth_info = json.load(f)\n",
    "        tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r2ycJsJCB02o",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "################################# DATA INPUT ###################################\n",
    "\n",
    "def parser(serialized_example):\n",
    "        \"\"\"Parses a single example into image and label tensors.\"\"\"\n",
    "        features = tf.parse_single_example(\n",
    "            serialized_example,\n",
    "            features={\n",
    "                'image_content': tf.FixedLenFeature([], tf.string),\n",
    "                'image_style': tf.FixedLenFeature([], tf.string),\n",
    "                'label': tf.FixedLenFeature([], tf.int64) \n",
    "            })\n",
    "\n",
    "        content_image = tf.decode_raw(features['image_content'], tf.uint8)\n",
    "        content_image.set_shape([48 * 48 * 4])\n",
    "        content_image = tf.reshape(content_image, [48, 48, 4])[:,:,:CHANNELS]\n",
    "        # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
    "        content_image = tf.cast(content_image, dtype=tf.float32) / 127.5 - 1\n",
    "\n",
    "        style_image = tf.decode_raw(features['image_style'], tf.uint8)\n",
    "        style_image.set_shape([48 * 48 * 4])\n",
    "        style_image = tf.reshape(style_image, [48, 48, 4])[:,:,:CHANNELS]\n",
    "        # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
    "        style_image = tf.cast(style_image, dtype=tf.float32) / 127.5 - 1\n",
    "        \n",
    "        label = features['label']\n",
    "\n",
    "        return style_image, content_image, label\n",
    "\n",
    "\n",
    "def make_input_fn(is_training=True):\n",
    "    def input_fn(params):\n",
    "        batch_size = params['batch_size']\n",
    "        dataset = tf.data.TFRecordDataset(data_train_file).map(parser).cache().shuffle(batch_size)\n",
    "        if is_training:\n",
    "            dataset = dataset.repeat()\n",
    "        style_images, content_images, labels = \\\n",
    "            dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
    "\n",
    "        features = {\n",
    "            'style_images': style_images,\n",
    "            'content_images': content_images\n",
    "        }\n",
    "        return features, labels\n",
    "    return input_fn\n",
    "\n",
    "\n",
    "def predict_input_fn(params):\n",
    "    batch_size = params['batch_size']\n",
    "    dataset = tf.data.TFRecordDataset(data_test_file).map(parser).cache().shuffle(batch_size)\n",
    "    style_images, content_images = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
    "    \n",
    "    features = {\n",
    "        'style_images': style_images,\n",
    "        'content_images': content_images,\n",
    "    }\n",
    "    return features, None\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P6i0DewZB02v",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "############################### DATA SAVEING ###################################\n",
    " \n",
    "def images_to_zero_one(images):\n",
    "        return np.clip(np.array(images) * 0.5 + 0.5, 0., 1.)\n",
    "\n",
    "\n",
    "def save_imgs(epoch, images):\n",
    "    if not os.path.exists(GOOGLE_DRIVE_DIR):\n",
    "        os.mkdir(GOOGLE_DRIVE_DIR)\n",
    "\n",
    "    # Rescale images to 0 - 1\n",
    "    images = images_to_zero_one(images)\n",
    "    fig, axs = plt.subplots(R, C, figsize=(20,20))\n",
    "\n",
    "    for i in range(R):\n",
    "        for j in range(C):\n",
    "            axs[i,j].imshow(images[C*i + j])\n",
    "            axs[i,j].axis('off')\n",
    "\n",
    "    fig.savefig(os.path.join(GOOGLE_DRIVE_DIR, '{}.png'.format(epoch)))\n",
    "    plt.close()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "khVvoOzKB024",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "################################## MODEL #######################################\n",
    "\n",
    "def _relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def _leaky_relu(x):\n",
    "    return tf.nn.leaky_relu(x, alpha=ALPHA)\n",
    "\n",
    "\n",
    "def _batch_norm(x, is_training, name):\n",
    "    return tf.layers.batch_normalization(x, momentum=0.8, epsilon=1e-5, \n",
    "                                         training=is_training, name=name)\n",
    "\n",
    "\n",
    "def _dense(x, neurons, name, activation=None):\n",
    "    return tf.layers.dense(x, neurons, name=name, activation=activation,\n",
    "                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "\n",
    "def _conv2d(x, filters, stride, name, activation=None):\n",
    "    return tf.layers.conv2d(x, filters, [KERNEL_SIZE, KERNEL_SIZE], \n",
    "                            strides=[stride, stride], activation=activation,\n",
    "                            padding='same', name=name,\n",
    "                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "\n",
    "def _instance_norm(x, activation=None):\n",
    "    return tf.contrib.layers.instance_norm(x, activation=activation)\n",
    "\n",
    "def _pooling(x, stride, index):\n",
    "    return tf.layers.average_pooling2d(x, pool_size=stride, strides=stride, name='pool_{}'.format(index))\n",
    "\n",
    "def _deconv2d(x, filters, stride, name, activation=None):\n",
    "    return tf.layers.conv2d_transpose(x, filters, [KERNEL_SIZE, KERNEL_SIZE],\n",
    "                                      strides=[stride, stride], activation=activation,\n",
    "                                      padding='same', name=name,\n",
    "                                      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "\n",
    "def convolution_block(x, filters, resize_factor, index, activation=_relu, activation_first=False, normalization=None):\n",
    "    if activation and activation_first:\n",
    "        x = activation(x)\n",
    "    x = _conv2d(x, filters=filters, stride=resize_factor, activation=None, name='conv_{}'.format(index))\n",
    "    if normalization:\n",
    "        x = normalization(x)\n",
    "    if activation and not activation_first:\n",
    "        x = activation(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def deconvolution_block(x, filters, resize_factor, index, activation=_relu, normalization=None):\n",
    "    x = _deconv2d(x, filters=filters, stride=resize_factor, activation=None, name='deconv_{}'.format(index))\n",
    "    if normalization:\n",
    "        x = normalization(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def fully_connected_block(x, neurons, index, activation=_relu, normalization=None):\n",
    "    x = _dense(x, neurons=neurons, activation=None, name='fc_{}'.format(index))\n",
    "    if normalization:\n",
    "        x = normalization(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def residual_block(x, filters, index, activation=_relu, activation_first=False, normalization=None):\n",
    "    forwarded_x = convolution_block(x, filters, 1, index='con_{}'.format(index), activation_first=activation_first, activation=activation)\n",
    "    forwarded_x = convolution_block(forwarded_x, filters, 1, index='con_{}'.format(index), activation_first=activation_first, activation=activation)\n",
    "    x = tf.add(forwarded_x, x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def adain_residual_block(x, filters, index, activation=_relu, activation_first=False, normalization=None):\n",
    "    pass\n",
    "\n",
    "\n",
    "def content_encoder(x):\n",
    "    x = convolution_block(x, 64, resize_factor=1, normalization=_instance_norm, index='con1')\n",
    "    x = convolution_block(x, 128, resize_factor=2, normalization=_instance_norm, index='con2')\n",
    "    x = convolution_block(x, 256, resize_factor=2, normalization=_instance_norm, index='con3')\n",
    "    x = convolution_block(x, 512, resize_factor=2, normalization=_instance_norm, index='con4')\n",
    "    \n",
    "    x = residual_block(x, 512, index='res1', normalization=_instance_norm)\n",
    "    x = residual_block(x, 512, index='res2', normalization=_instance_norm)\n",
    "    return x\n",
    "\n",
    "\n",
    "def decoder(content_latent, class_latent):    \n",
    "    # class_latent = fully_connected_block(class_latent, 256, 'dec11')\n",
    "    # class_latent = fully_connected_block(class_latent, 256, 'dec12')\n",
    "    # class_latent = fully_connected_block(class_latent, 256, 'dec13')\n",
    "\n",
    "    x = deconvolution_block(content_latent, 256, resize_factor=2, normalization=_instance_norm, index='dec1')\n",
    "    x = deconvolution_block(x, 128, resize_factor=2, normalization=_instance_norm, index='dec2')\n",
    "    x = deconvolution_block(x, 64, resize_factor=2, normalization=_instance_norm, index='dec3')\n",
    "    x = deconvolution_block(x, 3, resize_factor=1, normalization=_instance_norm, index='dec4', activation=tf.tanh)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def class_encoder(x):\n",
    "    x = convolution_block(x, 64, resize_factor=1, index='cls1')\n",
    "    x = convolution_block(x, 128, resize_factor=2, index='cls2')\n",
    "    x = convolution_block(x, 256, resize_factor=2, index='cls3')\n",
    "    x = convolution_block(x, 512, resize_factor=2, index='cls4')\n",
    "    x = convolution_block(x, 1024, resize_factor=2, index='cls5')\n",
    "    x = _pooling(x, 3, index='cls6')\n",
    "    return x\n",
    "\n",
    "class Funit:\n",
    "\n",
    "    @staticmethod\n",
    "    def discriminator(x, label, scope='Discriminator'):\n",
    "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "            x = convolution_block(x, 64, 1, index='disc_11')\n",
    "            \n",
    "            x = residual_block(x, 128, 'disc_12', _leaky_relu, activation_first=True)\n",
    "            x = residual_block(x, 128, 'disc_13', _leaky_relu, activation_first=True)\n",
    "            x = _pooling(x, 2, 'disc_14')\n",
    "            \n",
    "            x = residual_block(x, 256, 'disc_15', _leaky_relu, activation_first=True)\n",
    "            x = residual_block(x, 256, 'disc_16', _leaky_relu, activation_first=True)\n",
    "            x = _pooling(x, 2, 'disc_17')\n",
    "            \n",
    "            x = residual_block(x, 512, 'disc_18', _leaky_relu, activation_first=True)\n",
    "            x = residual_block(x, 512, 'disc_19', _leaky_relu, activation_first=True)\n",
    "            x = _pooling(x, 2, 'disc_20')\n",
    "            \n",
    "            x = residual_block(x, 1024, 'disc_21', _leaky_relu, activation_first=True)\n",
    "            x = residual_block(x, 1024, 'disc_22', _leaky_relu, activation_first=True)\n",
    "            x = _pooling(x, 2, 'disc_23')\n",
    "            \n",
    "            x = residual_block(x, 1024, 'disc_24', _leaky_relu, activation_first=True)\n",
    "            x = residual_block(x, 1024, 'disc_25', _leaky_relu, activation_first=True)\n",
    "            \n",
    "            x = convolution_block(x, NUM_CLASSES, 1, index='disc_26', activation=_leaky_relu, activation_first=True)\n",
    "            \n",
    "            return x\n",
    "\n",
    "    @staticmethod\n",
    "    def generator(image_content, image_style, scope='Generator'):\n",
    "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "            content_latent = content_encoder(image_content)\n",
    "            class_latent = class_encoder(image_style)\n",
    "            \n",
    "            x = decoder(content_latent, class_latent)\n",
    "            return x"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gcr7UF8SB029",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "################################ MODEL FUN #####################################\n",
    "\n",
    "def make_model_fn(model):\n",
    "    def model_fn(features, labels, mode, params):\n",
    "        # PREDICT #\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            content_images = features['content_images']\n",
    "            style_images = features['style_images']\n",
    "            generated_images = model.generator(content_images, style_images)\n",
    "            predictions = {\n",
    "                'generated_images': generated_images,\n",
    "                'content_images': content_images,\n",
    "                'style_images': style_images\n",
    "            }\n",
    "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "        content_images = features['content_images']\n",
    "        style_images = features['style_images']\n",
    "        generated_images = model.generator(content_images, style_images)\n",
    "\n",
    "        # Discriminator loss\n",
    "        d_on_data_logits = tf.squeeze(model.discriminator(style_images, labels))\n",
    "        d_on_data_labels = tf.ones_like(d_on_data_logits)\n",
    "\n",
    "        d_on_g_logits = tf.squeeze(model.discriminator(generated_images, labels))\n",
    "        d_on_g_labels = tf.zeros_like(d_on_g_logits)\n",
    "\n",
    "        d_loss = tf.contrib.gan.losses.wargs.modified_discriminator_loss(\n",
    "            discriminator_real_outputs=d_on_data_logits,\n",
    "            discriminator_gen_outputs=d_on_g_logits,\n",
    "            reduction=tf.losses.Reduction.NONE,\n",
    "            label_smoothing=0.2\n",
    "        )\n",
    "\n",
    "        # Generator loss\n",
    "        g_loss = tf.contrib.gan.losses.wargs.modified_generator_loss(\n",
    "            discriminator_gen_outputs=d_on_g_logits,\n",
    "            reduction=tf.losses.Reduction.NONE\n",
    "        )\n",
    "\n",
    "        # TRAIN #\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            d_loss = tf.reduce_mean(d_loss)\n",
    "            g_loss = tf.reduce_mean(g_loss)\n",
    "            d_optimizer = tf.train.AdamOptimizer(learning_rate=D_LR, beta1=0.5)\n",
    "            g_optimizer = tf.train.AdamOptimizer(learning_rate=G_LR, beta1=0.5)\n",
    "\n",
    "            d_optimizer = tf.contrib.tpu.CrossShardOptimizer(d_optimizer)\n",
    "            g_optimizer = tf.contrib.tpu.CrossShardOptimizer(g_optimizer)\n",
    "\n",
    "            with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "                d_step = d_optimizer.minimize(d_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                                                                                 scope='Discriminator'))\n",
    "                g_step = g_optimizer.minimize(g_loss, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                                                                                 scope='Generator'))\n",
    "\n",
    "                increment_step = tf.assign_add(tf.train.get_or_create_global_step(), 1)\n",
    "                joint_op = tf.group([d_step, g_step, increment_step])\n",
    "\n",
    "                return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=g_loss, train_op=joint_op)\n",
    "\n",
    "        # EVAL #\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            def _eval_metric_fn(d_loss, g_loss, d_real_labels, d_gen_lanels, d_real_logits, d_gen_logits):\n",
    "                return {\n",
    "                    'discriminator_loss': tf.metrics.mean(d_loss),\n",
    "                    'generator_loss': tf.metrics.mean(g_loss),\n",
    "                    'discriminator_real_accuracy': tf.metrics.accuracy(labels=d_real_labels, predictions=tf.math.round(tf.sigmoid(d_real_logits))),\n",
    "                    'discriminator_gen_accuracy': tf.metrics.accuracy(labels=d_gen_lanels, predictions=tf.math.round(tf.sigmoid(d_gen_logits))),\n",
    "                }\n",
    "\n",
    "            return tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=tf.reduce_mean(g_loss),\n",
    "                                                   eval_metrics=(_eval_metric_fn, [d_loss, g_loss, d_on_data_labels,\n",
    "                                                                                   d_on_g_labels, d_on_data_logits, d_on_g_logits]))\n",
    "    return model_fn"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-5rb586jB03F",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "################################ ESTIMATORS ####################################\n",
    "\n",
    "def make_estimators(model, only_cpu=False):\n",
    "    model_fn = make_model_fn(model)\n",
    "    \n",
    "    config = tf.contrib.tpu.RunConfig(\n",
    "        master=TF_MASTER,\n",
    "        save_checkpoints_steps=EVAL_EPOCHS,\n",
    "        save_checkpoints_secs=None,\n",
    "        save_summary_steps=EVAL_EPOCHS,\n",
    "        model_dir=MODEL_DIR,\n",
    "        keep_checkpoint_max=3,\n",
    "        tpu_config=tf.contrib.tpu.TPUConfig(iterations_per_loop=EVAL_EPOCHS))\n",
    "\n",
    "    if not only_cpu:\n",
    "        # TPU-based estimator used for TRAIN and EVAL\n",
    "        est = tf.contrib.tpu.TPUEstimator(\n",
    "            model_fn=model_fn,\n",
    "            use_tpu=True,\n",
    "            config=config,\n",
    "            train_batch_size=BATCH_SIZE,\n",
    "            eval_batch_size=BATCH_SIZE)\n",
    "    else:\n",
    "        est = None\n",
    "\n",
    "    # CPU-based estimator used for PREDICT (generating images)\n",
    "    cpu_est = tf.contrib.tpu.TPUEstimator(\n",
    "        model_fn=model_fn,\n",
    "        use_tpu=False,\n",
    "        config=config,\n",
    "        predict_batch_size=EXAMPLES)\n",
    "    \n",
    "    return est, cpu_est"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7nIuQqdWB03O",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "################################# TRAINING #####################################\n",
    "\n",
    "def train(est, cpu_est):\n",
    "    current_step = estimator._load_global_step_from_checkpoint_dir(MODEL_DIR)\n",
    "    tf.logging.info('Starting training')\n",
    "\n",
    "    while current_step < EPOCHS:\n",
    "        next_checkpoint = int(min(current_step + EVAL_EPOCHS, EPOCHS))\n",
    "        est.train(input_fn=make_input_fn(), max_steps=next_checkpoint)\n",
    "        current_step = next_checkpoint\n",
    "        tf.logging.info('Finished training step %d' % current_step)\n",
    "\n",
    "        # Evaluation\n",
    "        metrics = est.evaluate(input_fn=make_input_fn(False), steps=1)\n",
    "        tf.logging.info('Finished evaluating')\n",
    "        tf.logging.info(metrics)\n",
    "\n",
    "        # Render some generated images\n",
    "        generated_iter = cpu_est.predict(input_fn=predict_input_fn)\n",
    "        images = [np.concatenate([p['image_input'], p['generated_images']], axis=1) for p in generated_iter]\n",
    "        save_imgs('predict', images)\n",
    "        tf.logging.info('Finished generating images')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "STjYktznB03T",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def do_experiment():\n",
    "    setup()\n",
    "    upload_credentials()\n",
    "    model = Funit()\n",
    "    est, cpu_est = make_estimators(model)\n",
    "    train(est, cpu_est)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mS5ajICgBpCO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# def predict_on_image(image, cpu_est):\n",
    "# \n",
    "#     def image_predict_input_fn(params):\n",
    "#         batch_size = params['batch_size']\n",
    "#         images = np.zeros((batch_size, 48, 48, 4))\n",
    "#         images[0,:,:,:] = image\n",
    "#         dataset = tf.data.Dataset.from_tensors(images)\n",
    "#         input_images, _ = dataset.prefetch(batch_size).batch(batch_size, drop_remainder=True).make_one_shot_iterator().get_next()\n",
    "#         return {'image_input': input_images}, None\n",
    "# \n",
    "#     generated_iter = cpu_est.predict(input_fn=image_predict_input_fn)\n",
    "#     images = [np.concatenate([p['image_input'], p['generated_images']], axis=1) for p in generated_iter]\n",
    "#     plt.imshow(images[0])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y8nJTGZfCI5h",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "outputId": "b104a1bb-18a2-40e0-ea08-90ddb2a9c53d"
   },
   "source": [
    "# setup()\n",
    "# upload_credentials()\n",
    "# model = Pix2Pix()\n",
    "# _, cpu_est = make_estimators(model, only_cpu=True)"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Estimator's model_fn (<function make_model_fn.<locals>.model_fn at 0x7fa0a1fd7b70>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://tputestingmnist/Pix2Pix_2/', '_tf_random_seed': None, '_save_summary_steps': 5000, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa0b1381e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.33.129.154:8470', '_evaluation_master': 'grpc://10.33.129.154:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=5000, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WDvqThn2CPjf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# plt.imread()\n",
    "# predict_on_image(, cpu_est)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1vdQ83GWB03c",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "R, C = 4, 3\n",
    "EXAMPLES = R * C\n",
    "    \n",
    "CHANNELS = 4\n",
    "LATENT_DIM = 128\n",
    "ADD_NOISE_TO_EXAMPLE = False\n",
    "\n",
    "DROPOUT_PROB = 0.5\n",
    "ALPHA = 0.2\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 100000\n",
    "EVAL_EPOCHS = 5000\n",
    "G_LR = 0.0002\n",
    "D_LR = 0.0001\n",
    "KERNEL_SIZE = 4\n",
    "NUM_CLASSES = 21\n",
    "\n",
    "RUN_NAME = 'FUNIT_0'\n",
    "\n",
    "data_train_file = 'gs://tputestingmnist/datasets/dataset_train_funit.tfrecords'\n",
    "data_test_file = 'gs://tputestingmnist/datasets/dataset_test_funit.tfrecords'\n",
    "MODEL_DIR = 'gs://tputestingmnist/{}/'.format(RUN_NAME)\n",
    "GOOGLE_DRIVE_DIR = '/content/gdrive/My Drive/Programowanie/PixelGen/{}'.format(RUN_NAME)\n",
    "TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
    "\n",
    "# try:\n",
    "#     do_experiment()\n",
    "# except Exception as e:\n",
    "#     print (e)\n",
    "#     pass"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3eImay3kpN2C",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}